{
  "doc_id": "1806.07406",
  "nodes": [
    {
      "id": 0,
      "text": "Contrastive Hebbian Lea rning with Random Feedback Weights",
      "label_id": 0,
      "label_name": "Title",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 1,
      "text": "Georgios Detorakis, Travis Bartley, and Emre Neftci",
      "label_id": 1,
      "label_name": "Author",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 2,
      "text": "Abstract",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 3,
      "text": "Neural networks are commonly trained to make predictions through learning algorithms. Contrastive",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 2,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 4,
      "text": "Hebbian learning, which is a powerful rule inspired by gradient backpropagation, is based on Hebb’s",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 3,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 5,
      "text": "rule and the contrastive divergence algorithm. It operates in two phases, the forward (or free) phase,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 4,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 6,
      "text": "where the data are fed to the network, and a backward (or clamped) phase, where the target signals",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 5,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 7,
      "text": "are clamp ed to the output layer of the network and the feedback signals are transformed through the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 6,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 8,
      "text": "transpose synaptic weight matrices. This implies symmetries at the synaptic level, for which there is",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 7,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 9,
      "text": "no evidence in the brain. In this work, we prop ose a new variant of the algorithm, called random",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 8,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 10,
      "text": "contrastive Hebbian learning, which does not rely on any synaptic weights symmetries. Instead, it uses",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 9,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 11,
      "text": "random matrices to transform the feedback signals during the clamped phase, and the neural dynamics",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 10,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 12,
      "text": "are described by first order non-linear differential equations. The algorithm is experimentally verified by",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 11,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 13,
      "text": "solving a Boolean logic task, classification tasks (handwritten digits and letters), and an autoencoding",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 12,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 14,
      "text": "task. This article also shows how the parameters affect learning, esp ecially the random matrices. We",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 13,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 15,
      "text": "use the pseudospectra analysis to investigate further how random matrices impact the learning pro cess.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 14,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 16,
      "text": "Finally, we discuss the biological plausibility of the proposed algorithm, and how it can give rise to b etter",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 15,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 17,
      "text": "computational models for learning.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 16,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 18,
      "text": "1 Intro duction",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 2,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 19,
      "text": "Learning is one of the fundamental aspects of any living organism, regardless of their complexity. From",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 18,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 20,
      "text": "less complex biological entities such as viruses [9], to highly complex primates [14, 17], learning is of vital",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 19,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 21,
      "text": "importance for survival and evolution. Research in neuroscience has dedicated significant effort to under-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 20,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 22,
      "text": "standing the mechanisms and principles that govern learning in highly complex organisms, such as rodents",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 21,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 23,
      "text": "and primates. Both Hebbian learning [14] and spike-timing dependent plasticity (STDP) [4, 28, 51] have",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 22,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 24,
      "text": "had high impact on mo dern computational neuroscience, since both Hebb and STDP rules solve the prob-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 23,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 25,
      "text": "lem of adaptation in the nervous system and can account for explaining synaptic plasticity [2, 6]. On the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 24,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 26,
      "text": "other hand, the field of machine learning has made progress using gradient backpropagation (BP) [42, 8]",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 25,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 27,
      "text": "in deep neural networks, providing state-of-the-art solutions to a variety of classification and representation",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 26,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 28,
      "text": "tasks [20].",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 27,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 29,
      "text": "Despite this progress, most learning algorithms employed with artificial neural networks are implausible",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 19,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 30,
      "text": "from a biological standpoint, this is esp ecially true for methods based on BP. In particular, some of the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 29,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 31,
      "text": "more common properties that are implausible are (i) the requirement of symmetric weights, (ii) neurons",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 30,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 32,
      "text": "that do not have temporal dynamics (i.e., neural dynamics are not described by autonomous dynamical",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 31,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 33,
      "text": "systems or maps as in the case of recurrent neural networks), (iii) the derivatives of the non-linearities have",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 32,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 34,
      "text": "to b e computed for each layer with high precision, (iv) the flow of information in the neural network is not",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 33,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 35,
      "text": "similar to the one in real biological systems (synchronization b etween different phases–forward, backward–",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 34,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 36,
      "text": "is required), and (v) the backward phase requires the neural activity of the forward phase to b e stored.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 35,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 37,
      "text": "In the aforementioned context there are attempts to make Machine Learning algorithms more biologically",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 29,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 38,
      "text": "plausible. Such a biologically plausible alternative to BP is the target propagation algorithm [21]. The",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 37,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 39,
      "text": "target propagation algorithm computes local errors at each layer of the network using information about the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 38,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 40,
      "text": "target, which is propagated instead of the error signal as in classical BP. However, target propagation still",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 39,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 41,
      "text": "computes derivatives (locally) and requires symmetries at the synaptic level. Another biologically plausible",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 40,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 42,
      "text": "1",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 43,
      "text": "learning algorithm is the recirculation algorithm [16] and its generalization the GeneRec [38], where the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 41,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 44,
      "text": "neural network has some recurrent connections that propagate the error signals from the output layer to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 43,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 45,
      "text": "the hidden(s) one(s) via symmetric weights. Furthermore, the recirculation algorithm does not preserve",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 44,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 46,
      "text": "the symmetries at the synaptic level, though GeneRec is still based on derivatives and back-propagation of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 45,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 47,
      "text": "error signals. Moreover, all the aforementioned algorithms require a specific pattern of information flow.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 46,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 48,
      "text": "Every layer should wait for the previous one to reach its equilibrium and then to proceed in receiving and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 47,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 49,
      "text": "processing the incoming information. This issue can be circumvented by the Contrastive Hebbian learning",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 48,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 50,
      "text": "(CHL, deterministic Boltzmann Machine or a mean field approach) [31, 3, 50], which is similar to the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 49,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 51,
      "text": "contrastive divergence algorithm [15]. CHL is based on the Hebbian learning rule and do es not require",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 50,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 52,
      "text": "knowledge of any derivatives. Moreover, due to its non-linear continuous coupled dynamics the information",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 51,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 53,
      "text": "flows in a continuous way. All the neural activities in all the layers may b e up dated simultaneously without",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 52,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 54,
      "text": "waiting for the convergence of previous or subsequent layers. However, CHL requires synaptic symmetries",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 53,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 55,
      "text": "since it relies on the transpose of the synaptic matrix to propagate backwards the feedback signals.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 54,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 56,
      "text": "Motivated to create a more biologically plausible CHL, we proposed random Contrastive Hebbian learning",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 37,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 57,
      "text": "(rCHL), which avoids the use of symmetric synaptic weights, instead replacing the transpose of the synaptic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 56,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 58,
      "text": "weights in CHL with fixed random matrices. This was performed in a manner similar to that of Feedback",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 57,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 59,
      "text": "Alignment (FDA) [22, 35, 33]. CHL provides a goo d basis upon which to develop biologically realistic learning",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 58,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 60,
      "text": "rules because it employs continuous nonlinear dynamics at the neuronal level, do es not rely on gradients,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 59,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 61,
      "text": "allows information to flow in a coupled, synchronous way, and, is grounded up on Hebb’s learning rule. CHL",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 60,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 62,
      "text": "uses feedback to transmit information from the output layer to hidden(s) layer(s), and in instances when",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 61,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 63,
      "text": "the feedback gain is small (such as in the clamp ed phase), has b een demonstrated by Xie and Seung to be",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 62,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 64,
      "text": "equivalent to BP [50].",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 63,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 65,
      "text": "Using this approach, the information necessary for learning propagates backwards, though it is not",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 56,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 66,
      "text": "transmitted through the same axons (as required in the symmetric case), but instead via separate pathways",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 65,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 67,
      "text": "or neural populations. Therefore, the randomness we introduce may account for the structure and dynamics",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 66,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 68,
      "text": "of other cerebral areas interfering with the transmitted signals of interest or feed-back projections as occur",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 67,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 69,
      "text": "in the visual system [27, 25, 24, 43]. By this we do not necessarily imply that the brain implements random",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 68,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 70,
      "text": "transformations, instead thatthe random matrices being used here in plac e of transp ose synaptic matrices",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 69,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 71,
      "text": "may b e thought of in a more general sense as instruments for modeling unknown or hard-to-model dynamics",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 70,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 72,
      "text": "within the brain.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 71,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 73,
      "text": "The proposed learning scheme can b e used in different contexts, as demonstrated on several learning",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 65,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 74,
      "text": "tasks. We show how rCHL can cop e with (i) binary operations such as the XOR, (ii) classifying handwritten",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 73,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 75,
      "text": "digits and letters, and (iii) autoencoding. In most of these cases, the performance (in terms of the mean",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 74,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 76,
      "text": "squared error) of rCHL was either equivalent or similar to BP, FDA, and CHL, suggesting that rCHL can",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 75,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 77,
      "text": "be a potential candidate for general biologically plausible learning models.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 76,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 78,
      "text": "2 Materials and Methods",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 18,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 79,
      "text": "In this section we summarize Contrastive Hebbian learning (CHL) [50] and intro duce random Contrastive",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 78,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 80,
      "text": "Hebbian learning (rCHL). We assume feed-forward networks along with their corresponding feed-backs. L",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 79,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 81,
      "text": "is the total number of layers with 1 being the input layer and L the output one. Connections from layer",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 80,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 82,
      "text": "k − 1 to k are given by a matrix Wk ∈ Rm×n where m and n are the sizes of the k − 1 and k layers (number",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 81,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 83,
      "text": "of neurons), respectively. Feedback connections are given by Vk ∈ Rn×m, which can be either a transpose",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 82,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 84,
      "text": "(in the case of CHL) or a random matrix Gk ∈ Rn×m in the case of random CHL. In both CHL matrix W",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 83,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 85,
      "text": "and rCHL, the feedback connections are multiplied by a constant gain, γ ∈ R. We define the non-linearities",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 84,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 86,
      "text": "as Lipschitz continuous functions fk : Rn → Rn, with Lipschitz constant αk (i.e. |fk(x) − fk(y)| ≤ αk |x − y|,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 85,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 87,
      "text": "∀x, y ∈ R, k ∈ N). The state of a neuron in the k-th layer is described by the state function xik : R → R,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 86,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 88,
      "text": "and the corresponding bias is given by bik ∈ R. The dynamics of all neurons at the k-th layer are given by:",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 87,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 89,
      "text": "dxk dt = −xk + fk (cid:0)Wk · xk−1 + γVk+1 · xk +1 + bk (cid:1). (1)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 88,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 90,
      "text": "2",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 91,
      "text": "2.1 Contrastive Hebbian Learning",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 78,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 92,
      "text": "Both CHL and the proposed rCHL operate on the same principle as contrastive divergence [15]. This means",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 91,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 93,
      "text": "that learning takes place in two phases. In the p ositive (free) phase, the input is presented and the output is",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 92,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 94,
      "text": "built by forward propagation of neural activities. In the negative (clamped) phase, the outputs are clamp ed,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 93,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 95,
      "text": "and the activity is propagated backwards towards the input layer.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 94,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 96,
      "text": "In the free phase, the input layer x0 is held fixed, and the signals are propagated forward through each",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 92,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 97,
      "text": "layer (see the red arrows in figures 1). The dynamics of the neurons at each k-th layer are computed through",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 96,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 98,
      "text": "the equation (1) for k = 1, . . . , L (the L + 1 layer do es not exist and thus xL+1 = 0 and WL+1 = 0). During",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 97,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 99,
      "text": "the clamped phase, the target signal is clamped at the output layer xL and the activity of all the neurons",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 98,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 100,
      "text": "in every layer is computed through equation (1) for k = 1, . . . , L − 1 (notice here that the input layer k = 0",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 99,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 101,
      "text": "does not express any dynamics). The backward flow is illustrated as cyan arrows in figure 1. At the end of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 100,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 102,
      "text": "the two phases we update the synaptic weights and the biases based on the following equations,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 101,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 103,
      "text": "∆Wk = ηγ k−L (cid:0) ˆxk ⊗ ˆxk−1 − ˇxk ⊗ ˇxk−1 (cid:1), k = 1, . . . , L, (2a) ∆bk = ηγ k−L (cid:16) ˆxk − ˇxk (cid:17) (2b)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 102,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 104,
      "text": "where ⊗ is the tensor product, η is the learning rate, γ is the feedback gain, and ∆Wk is weight update.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 103,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 105,
      "text": "ˇxk represents the activity of neurons in the k-th layer at the equilibrium configuration of equation (1) in the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 104,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 106,
      "text": "free phase and ˆxk the activity of the k-th layer in the clamp ed phase.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 105,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 107,
      "text": "2.2 Random Contrastive Hebbian Learning",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 91,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 108,
      "text": ") in order As described by equation (1), CHL implicitly requires the synaptic weights to b e symmetric (W",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 107,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 109,
      "text": "to use the feedback information. In this work, the main contribution is to cast aside the symmetry and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 108,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 110,
      "text": "replace all the transpose matrices that appear in CHL with random matrices Gk. This idea is similar to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 109,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 111,
      "text": "random feedback alignment [22, 35], where the error signals are propagated back through random matrices",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 110,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 112,
      "text": "that remain constant during learning. Therefore, equation (1) is modified to the following:",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 111,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 113,
      "text": "dxk dt = −xk + fk (cid:0)Wk · xk −1 + γGk +1 · xk+1 + bk (cid:1), (3)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 112,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 114,
      "text": "where the learning increments remain the same. In order to properly apply CHL and rCHL, we follow",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 113,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 115,
      "text": "the second strategy of training prop osed by Movellan in [31] (pg. 12, case 2), suggesting to first let activity",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 114,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 116,
      "text": "settle during the clamped phase. Then, without resetting activations, free the output units and allow activity",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 115,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 117,
      "text": "to settle again. This method assures that when the minimum for the clamped phase has been reached, it",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 116,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 118,
      "text": "remains stable.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 117,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 119,
      "text": "We summarize rCHL in Algorithm 1, where I is the input dataset, T is the corresponding target set, N",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 107,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 120,
      "text": "is the number of input samples, and L is the number of layers. The rCHL starts with randomly initializing",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 119,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 121,
      "text": "the synaptic weights and the feed-back random matrices. If the bias is not allowed to learn then it is fixed",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 120,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 122,
      "text": "at the very beginning. If it’s p ermitted to adapt then it is randomly initialized. Then in every epo ch rCHL",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 121,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 123,
      "text": "picks up randomly an input sample and assigns it to the input layer, ˇx0 . At the same time, it assigns the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 122,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 124,
      "text": "corresponding label (target) to the output layer ˆxL . Then it solves all the non-linear coupled differential",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 123,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 125,
      "text": "equations for each layer using a Forward Euler method for the backward phase. This means that it computes",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 124,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 126,
      "text": "the ˆxk and then it solves again the system of the coupled non-linear equations for the forward phase in order",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 125,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 127,
      "text": "to compute the ˇxk. Once all the activities for the forward and the backward phases have been computed,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 126,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 128,
      "text": "rCHL updates the synaptic weights and the biases, if they are allowed to b e updated, based on equations (2)a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 127,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 129,
      "text": "and b.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 128,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 130,
      "text": "Figure 1 illustrates the neural network architecture and the information flow of CHL (top panel) and",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 119,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 131,
      "text": "rCHL (bottom panel). In the forward pass, the input is provided and information is propagated through",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 130,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 132,
      "text": "matrices Wk . In the backward phase, the output is clamped, and the information flows from the output",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 131,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 133,
      "text": "layer to the hidden(s) through the transpose matrix Wk+1 (CHL) or random matrices Gk+1 (rCHL).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 132,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 134,
      "text": "3",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 135,
      "text": "0 Lk k+1WkFor ward FeedbackWk+1TCHL0 Lk k+1WkFor ward FeedbackGk+1rCHL",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 136,
      "text": "Figure 1: Learning scheme information flow. CHL (top panel) and rCHL (lower panel) are illustrated in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 135,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 137,
      "text": "this figure. Both CHL and rCHL consist of two phases. In the forward phase, the input signal is fed to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 136,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 138,
      "text": "the network, and the activity propagates up to the deep est layer through matrices Wk (red arrows). In the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 137,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 139,
      "text": "backward phase, the output (target) signal is clamped, whilst the input signal is still present and affects the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 138,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 140,
      "text": "neural dynamics. The activity is propagated backwards through matrix Wk+1 (navy color arrows) in the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 139,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 141,
      "text": "CHL and Gk+1 in the rCHL. It is clear that rCHL’s feedback mechanisms does not require any symmetries",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 140,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 142,
      "text": "and acts more like a feedback system on the dynamics of neurons conveying information from the k + 1-th",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 141,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 143,
      "text": "layer back to k -th layer.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 142,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 144,
      "text": "4",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 145,
      "text": "Algorithm 1 Random contrastive Hebbian learning (rCHL). I is the input dataset, T is the corresponding",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 146,
      "text": "target set (labels) of the input data set, and L is the numb er of layers of the network, tf is the simulation",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 145,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 147,
      "text": "time and dt the Forward Euler method’s time-step.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 146,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 148,
      "text": "TABLE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 145,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 149,
      "text": "3 Results",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 78,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 150,
      "text": "Next, we demonstrate rCHL on a variety of tasks. The algorithm successfully solves logical operations,",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 149,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 151,
      "text": "classification tasks and pattern generation problems. In the logical op erations and classification tasks we",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 150,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 152,
      "text": "compared our results against the state-of-the-art back-propagation (BP) and feed-back alignment (FDA). In",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 151,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 153,
      "text": "all rCHL and CHL simulations, we used the following settings, unless otherwise stated: time step dt = 0.08,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 152,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 154,
      "text": "total simulation time tf = 30ms, learning rate η = 0.1, and feedback gain γ = 0.05.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 153,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 155,
      "text": "3.1 Bars and Stripes Classification",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 149,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 156,
      "text": "We investigate how the parameters of the rCHL affect the learning process. In particular, we examine how",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 155,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 157,
      "text": "to select the random matrix G, the feedback gain γ , and the numb er of layers L. To this end we use the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 156,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 158,
      "text": "bars and stripes classification task to demonstrate the effect of the different parameters [23]. The dataset",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 157,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 159,
      "text": "consists of 32 binary images (black–0 and white–1) of size 4 × 4 representing bars and strip es, as shown in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 158,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 160,
      "text": "figure 2A. We train a network of of three layers (L = 3) with sizes 16 − 50 − 2 to classify the input data",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 159,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 161,
      "text": "into bars and stripes. During each epoch we pick up randomly one out of 32 images and present it to the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 160,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 162,
      "text": "5",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 163,
      "text": "network for 20, 000 epochs. Every 500 epo chs we freeze the learning and we test the performance of the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 161,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 164,
      "text": "network. We measure the Mean Square Error (MSE) (i.e., 1N (cid:80)Ni=1(yi − ˆyi)2 , where y is a reference signal",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 163,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 165,
      "text": "of N comp onents and ˆy is the estimated signal) and the accuracy of the network. All neurons have sigmoid",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 164,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 166,
      "text": "activation functions (fk(x) = 11+exp(−x) for all k = 1, . . . , L).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 165,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 167,
      "text": "The achieved test MSE is shown in figure 2B and the test accuracy in figure 2C. It is apparent that",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 156,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 168,
      "text": "rCHL converges, and the binary classification task has been learned after 5, 000 epochs. We tested two",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 167,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 169,
      "text": "different versions of rCHL, first we used the bias terms (cyan color in figure 2) in equation (3). All bk have",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 168,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 170,
      "text": "been initialized randomly from a uniform distribution U (−0.1, 0.1) and they are allowed to learn based on",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 169,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 171,
      "text": "equation (2). In the second case we set the bias terms to zero (purple color in figure 2). The same method",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 170,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 172,
      "text": "was also followed for CHL. Figures 2B and 2C indicate that CHL and rCHL can achieve similar results in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 171,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 173,
      "text": "the task. Once we have established the functionality of the rCHL, we investigate how the parameters of the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 172,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 174,
      "text": "random matrix G, the feedback gain γ, the learning rate η , and the number of layers L affect the learning.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 173,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 175,
      "text": "Therefore, we can conclude at that p oint that the rCHL has similar b ehavior with the CHL and the learning",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 174,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 176,
      "text": "Figure 2: Bars and stripes classification with rCHL. A Bars and stripes dataset used to train the neural",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 177,
      "text": "A 0 10 20 30 40Epochs (x500)0.00.10.20.30.40.5TestMSE B CHL_NoBiasCHL_BiasrCHL_NoBiasrCHL_Bias 0 10 20 30 40Epochs (x500)0.00.20.40.60.81.0TestAccuracy C CHL_NoBiasCHL_BiasrCHL_NoBiasrCHL_Bias",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 176,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 178,
      "text": "network. B the test MSE computed every 500 ep ochs. In every ep och, a stimulus (image) is presented to the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 176,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 179,
      "text": "network. Here, the rCHL algorithm (cyan and magenta curves) are compared against the CHL algorithm",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 178,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 180,
      "text": "(black and red curves). After 5, 000 ep ochs the network has converged. C Test accuracy of the network on",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 179,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 181,
      "text": "classifying the bars and strip es. We presented the entire dataset (32 images) during testing.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 180,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 182,
      "text": "process works as well as CHL’s. In the following paragraphs we are investigating how four basic parameters",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 175,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 183,
      "text": "of the mo del (learning rate, feed-back gain, number of layers, and the random matrix) affect the learning",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 182,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 184,
      "text": "using the Bars and Stripes classification task as toy model. We choose to not use the bias terms since they",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 183,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 185,
      "text": "do not affect the learning in this particular task.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 184,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 186,
      "text": "3.1.1 Feedback Gain",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 155,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 187,
      "text": "First we start with the feedback gain by sweeping it over the interval [0.01, 1.0], and drawing the initial",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 186,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 188,
      "text": "values of the synaptic weights as well as the random matrix from a uniform distribution U (−0.5, 0.5). The",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 187,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 189,
      "text": "effect of the feedback gain for standard CHL has been examined in [50]. In figures 3A and B, the test MSE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 188,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 190,
      "text": "and accuracy are shown for different values of γ . Lower feedback gain (about 0.1), works well for rCHL.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 189,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 191,
      "text": "Even when the feedback gain is around 0.0001 the learning pro cess still works (data not shown) and the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 190,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 192,
      "text": "convergence is fast. This is explained by the fact that the term γk −L in equation (2)(a) becomes extremely",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 191,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 193,
      "text": "large for small feedback gains for the very first layers and quite small for the deep er layers. On the other",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 192,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 194,
      "text": "hand, when when the feedback gain is high (e.g., γ = 1.0) the rCHL do es not converge (gray color in figure 3).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 193,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 195,
      "text": "3.1.2 Learning Rate",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 186,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 196,
      "text": "Another important parameter that affects learning is the rate the rCHL adjusts the synaptic weights, or the",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 195,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 197,
      "text": "learning rate η. Therefore, we use the same network architecture 16 − 50 − 2 and we keep fix the feedback",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 196,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 198,
      "text": "6",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 199,
      "text": "0 5 10 15 20 25 30 35 40Epochs (x500)0.00.10.20.30.40.50.6TestMSE A 0 5 10 15 20 25 30 35 40Epochs (x500)0.00.20.40.60.81.0TestAccuracy B = 0.01= 0.02= 0.03= 0.04= 0.05= 0.09= 0.1= 0.5= 1.0",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 200,
      "text": "Figure 3: Effect of feedback gain γ on bars and stripes classification. This figure illustrates the test MSE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 199,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 201,
      "text": "A and the test accuracy B for nine different values of feedback gain γ . Both panels illustrate that the neural",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 200,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 202,
      "text": "network trained using the rCHL algorithm learns to classify the bars and strip es dataset in all cases, except",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 201,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 203,
      "text": "where γ = 1.0. In this case, the MSE is high and the classification is unstable.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 202,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 204,
      "text": "gain γ = 0.05 and we vary the learning rate, i.e. η = {0.001, 0.005, 0.01, 0.05, 0.1, 0.5}. Figure 4 shows",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 197,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 205,
      "text": "the test error and accuracy for the various values of learning rate. When the learning rate is too low the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 204,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 206,
      "text": "learning diverges. On the other hand when the learning rate is higher the learning converges faster. For the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 205,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 207,
      "text": "values b etween 0.005 and 0.01 the learning converges smoother but takes more time to reach the equilibrium",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 206,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 208,
      "text": "in comparison to the higher values. In this case the random matrix and the synaptic weights have been",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 207,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 209,
      "text": "initialized by a uniform distribution U (−0.5, 0.5).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 208,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 210,
      "text": "0 50 100 150 200Epochs (x500)0.00.10.20.30.40.50.6TestMSE A 0 50 100 150 200Epochs (x500)0.00.20.40.60.81.0TestAccuracy B = 0.001= 0.005= 0.01= 0.05= 0.1= 0.5",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 211,
      "text": "Figure 4: Effect of learning rate η on bars and strip es classification. This figure illustrates the test MSE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 199,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 212,
      "text": "A and the test accuracy B for six different values of learning rate η . It is apparent that if the learning rate is",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 211,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 213,
      "text": "to o low the learning pro cess takes more time to converge. In this case we keep the feed-back gain constant",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 212,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 214,
      "text": "at γ = 0.5.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 213,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 215,
      "text": "3.1.3 Numb er of Layers",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 195,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 216,
      "text": "Next, we investigate how the number of hidden layers affects learning. To this end, we train four different",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 215,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 217,
      "text": "neural networks using rCHL. The configurations for the networks are 16 − 50 − 2 (L = 3), 16 − 50 − 10 − 2",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 216,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 218,
      "text": "(L = 4), 16 − 50 − 20 − 10 − 2 (L = 5), and 16 − 50 − 30 − 20 − 10 − 2 (L = 6). As before, we draw the synaptic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 217,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 219,
      "text": "weights and the random matrix from a uniform distribution U (−0.5, 0.5). Figures 5 A and B show the test",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 218,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 220,
      "text": "MSE and test accuracy of the networks. As we increase the number of layers, the rCHL networks fail to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 219,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 221,
      "text": "converge (data not shown). However, when we increase the feedback gain γ , convergence is achievable (gray",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 220,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 222,
      "text": "7",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 223,
      "text": "curves in figure 5). This behavior can be explained by the fact that the feedback gain affects the synaptic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 221,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 224,
      "text": "weight update by a factor γ k−L . This means that the more layers a network has, the higher γ should b e.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 223,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 225,
      "text": "Figure 5: Effect of numb er of layers L on bars and strip es classification. This figure illustrates the test",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 226,
      "text": "0 20 40 60 80 100 120Epochs (x500)0.00.10.20.30.40.50.6TestMSE A 0 20 40 60 80 100 120Epochs (x500)0.00.20.40.60.81.0TestAccuracy B L = 3L = 4L = 5L = 6, = 0.1",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 225,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 227,
      "text": "MSE A and the test accuracy B for four different values of L, which represents the number of layers. For",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 225,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 228,
      "text": "the largest value L = 6, rCHL diverges (data not shown) and we have to re-tune the feedback gain. Once",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 227,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 229,
      "text": "the feedback gain has b een increased, the convergence of rCHL is guaranteed (gray line).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 228,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 230,
      "text": "3.1.4 Feedback Random Matrix",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 215,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 231,
      "text": "The random feedback matrix plays a crucial role in the rCHL learning process. It conveys the information",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 230,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 232,
      "text": "from the output layer back to the hidden(s) one(s). Therefore, the feedback random matrix, essentially,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 231,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 233,
      "text": "alters the signals by applying the feedback from layer k + 1 to neural dynamics at layer k. Therefore, the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 232,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 234,
      "text": "learning process is directly affected by the choice of the feedback random matrices within the network. The",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 233,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 235,
      "text": "prop erties of random matrices arise from the distributions that generate them. In this case we investigate",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 234,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 236,
      "text": "how random matrices generated by a normal N (0, σ ) and a uniform U (a, b) distribution can impact the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 235,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 237,
      "text": "learning process. Furthermore, we define the length of the uniform distribution interval as ℓ = |b| + |a|.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 236,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 238,
      "text": "We start by varying the variance σ, and the length ℓ of the two different distributions. Next the network",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 231,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 239,
      "text": "is evaluated on the bars and stripes classification task, and the MSE and accuracy are recorded. Figures 6A",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 238,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 240,
      "text": "and B show the test MSE and accuracy, for sixteen different σ values for the normal distribution. As shown,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 239,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 241,
      "text": "the higher the variance, the faster convergence is reached. Figures 6 C and D indicate the test MSE and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 240,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 242,
      "text": "accuracy for sixteen different values of ℓ of the uniform distribution. In this case, we observe that the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 241,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 243,
      "text": "shorter the interval (smaller ℓ), the slower the convergence. Meanwhile, the wider the interval, the faster",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 242,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 244,
      "text": "and the convergence is. The convergence for short intervals is slower for the uniform distribution than for",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 243,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 245,
      "text": "corresponding small variance values for the normal distribution (see figures 6A and C).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 244,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 246,
      "text": "One of the key asp ects in Random Matrix Theory is the sp ectrum (i.e., eigenvalues) of the random matrix",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 238,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 247,
      "text": "and especially the distribution of the eigenvalues [48]. However, most connection matrices in neural networks",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 246,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 248,
      "text": "are not square and non-normal (i.e., VV∗ ̸= V∗ V, where V ∈ Rn×n). Therefore, one alternative to study",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 247,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 249,
      "text": "the spectrum of random matrices that are rectangular and non-normal is to study their singular values and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 248,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 250,
      "text": "the corresponding λϵ -pseudospectra [46, 47, 49] (we provide a brief description of the λϵ -pseudospectra in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 249,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 251,
      "text": "the App endix 5.1). The pseudospectra define a set of pseudo eigenvalues (λ) of a matrix A ∈ Rm×n, if",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 250,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 252,
      "text": "for some eigenvector υυυ with ||υυυ|| = 1 it holds ||(A − λ˜I)υυυ|| ≤ ϵ. Hence pseudospectra indicates p otential",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 251,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 253,
      "text": "sensitivity of eigenvalues under perturbations of the matrix A. In this study we are interested in identifying",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 252,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 254,
      "text": "spectral properties that can be related to the learning (i.e., convergence, speed of convergence, oscillations).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 253,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 255,
      "text": "Figure 7 illustrates the λϵ -pseudosp ectra for the random matrix G2 for the Bars and Strip es classification",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 246,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 256,
      "text": "task. We chose three cases for the uniform and three for the normal distribution from figure 6 and we then",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 255,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 257,
      "text": "applied on the random matrices the algorithm given in [49] to compute the λϵ -pseudosp ectra of G2 in each",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 256,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 258,
      "text": "case. In every panel the contour lines indicate the minimum singular values that correspond to different",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 257,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 259,
      "text": "8",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 260,
      "text": "0 20 40 60 80 100 1200.00.10.20.30.40.50.6TestMSE A 0 20 40 60 80 100 1200.00.20.40.60.81.0TestAccuracy B , = 0.01,0.02, = 0.02,0.04, = 0.03,0.06, = 0.04,0.08, = 0.05,0.1, = 0.09,0.18, = 0.1,0.2, = 0.2,0.4, = 0.3,0.6, = 0.4,0.8, = 0.5,1.0, = 0.6,1.2, = 0.7,1.4, = 0.8,1.6, = 0.9,1.8, = 1.0,2.00 20 40 60 80 100 120Epochs (x500)0.00.10.20.30.40.50.6TestMSE C 0 20 40 60 80 100 120Epochs (x500)0.00.20.40.60.81.0TestAccuracy D",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 261,
      "text": "Figure 6: Effect of matrix distribution on bars and stripes classification. This figure illustrates how",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 260,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 262,
      "text": "the random matrix G2 affects the learning pro cess when it is initialized from a normal and a uniform",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 261,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 263,
      "text": "distribution. A Test MSE for the normal distribution, B corresponding test accuracy. C Test MSE for",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 262,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 264,
      "text": "the uniform distribution, D corresponding test accuracy. The colored lines indicate different values for the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 263,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 265,
      "text": "variance σ of the normal distribution and the interval (length ℓ) of the uniform distribution (see the legend).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 264,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 266,
      "text": "The higher the variance or the length, the faster and more stable the convergence of the learning. The",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 265,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 267,
      "text": "network with configuration 16 − 50 − 2 performs a classification task on the bars and stripes dataset (see the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 266,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 268,
      "text": "text for more details).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 267,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 269,
      "text": "9",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 270,
      "text": "values of log10 (ϵ) on the complex plane. In addition in every panel we provide the corresponding test",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 258,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 271,
      "text": "MSE (inset plot). Subplots 7A B and C depict the pseudospectra of G2 drawn from uniform distributions",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 270,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 272,
      "text": "(U (−0.01, 0.01), U (−0.5, 0.5), U (−1, 1), respectively), as well as the test MSE. Likewise, subplots D, E, and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 271,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 273,
      "text": "F illustrate the cases of normal distributions (N (0, 0.01), N (0, 0.5), N (0, 1), resp ectively).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 272,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 274,
      "text": "Since the only varying parameter in this experiment is the way we generate the random matrix the",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 255,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 275,
      "text": "learning process is solely affected by that matrix. Therefore, in the cases A and D the pseudospectra of the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 274,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 276,
      "text": "two different distributions lo ok identical, whilst the test MSE has similar b ehavior, it decays slower (blue",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 275,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 277,
      "text": "and black lines in the insets). In both cases the minimum value for ϵ is the same (and around the origin).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 276,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 278,
      "text": "In the other cases B, C, E, and F the convergence of the test MSE toward zero is faster (inset) and less",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 277,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 279,
      "text": "violent (in terms of oscillations). The pseudosp ectra show higher minimum values for ϵ. For the uniform",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 278,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 280,
      "text": "distribution all the ϵ values are arranged on concentric circles. On the other hand, the normal distribution",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 279,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 281,
      "text": "with variances σ = 0.5 and σ = 1 causes a shift towards the right-half complex plane of the pseudospectrum.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 280,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 282,
      "text": "The minimum ϵ is higher in comparison to the uniform cases. One more remark is that for these four cases",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 281,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 283,
      "text": "the uniform distributions have smaller ϵ values in comparison to their normal counterparts. This might lead",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 282,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 284,
      "text": "to a less oscillatory behavior of the test MSE as it is shown in the insets (blue and black curves). In all",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 283,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 285,
      "text": "cases, we compute the pseudospectra using the implementation provided in [49]1.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 284,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 286,
      "text": "-4-2024 A ( 0.01, 0.01) 0.40.20.00.20.40.60.8 B ( 0.5, 0.5) 0.320.400.480.560.640.720.80 C ( 1, 1) 0.600.650.700.750.800.850.90-4 -2 0 2 4-4-2024 D (0, 0.01) 0.40.20.00.20.40.60.8 -4 -2 0 2 4E (0, 0.5) 0.550.600.650.700.750.800.85 -4 -2 0 2 4F (0, 1) 0.840.860.880.900.920.940.960.98",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 287,
      "text": "Figure 7: Λϵ -pseudospectra of G2 for the Bars and Stripes classification. Six different feedback random",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 286,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 288,
      "text": "matrices have been analyzed using the Λϵ -pseudosp ectra method. The colormap indicates the different",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 287,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 289,
      "text": "ϵ values. The top row shows the Λϵ for the matrices drawn by uniform distributions from intervals (A)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 288,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 290,
      "text": "(−0.01, 0.01), (B) (−0.5, 0.5), and (C) (−1, 1). The bottom row illustrates Λϵ for the random matrices",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 289,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 291,
      "text": "drawn from normal distributions with zero mean and variances (D) σ = 0.01, (E) σ = 0.5, and (F) σ = 1.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 290,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 292,
      "text": "3.2 Exclusive Or (XOR)",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 155,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 293,
      "text": "The exclusive or (denoted XOR or ⊕) problem consists of the evaluation of four possible Boolean input states",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 292,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 294,
      "text": "(i.e., 1 ⊕ 0 = 1, 1 ⊕ 1 = 0, 0 ⊕ 1 = 1, 0 ⊕ 0 = 0). To solve the XOR problem, we use a feed-forward network",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 293,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 295,
      "text": "with one hidden layer and one output layer (L = 3) with a configuration 2 − 2 − 1. All neural units are",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 294,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 296,
      "text": "sigmoidal: f (x) = (1 + exp(−x))−1 , and we train the neural network on the XOR problem for 5, 000 ep ochs",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 295,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 297,
      "text": "using CHL and rCHL. The random matrix G for rCHL has been initialized from a uniform distribution",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 296,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 298,
      "text": "U (−0.2, 0.2). In every ep och we present 128 samples to the network and every 500 epochs we measure the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 297,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 299,
      "text": "1 The source code can be found at: https://github.com/gdetor/pygpsa",
      "label_id": 13,
      "label_name": "Footnote",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 300,
      "text": "10",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 301,
      "text": "MSE and the accuracy on the test dataset. The accuracy here is defined to be 14 (cid:80)4i=1 |x2(t) − Ti| < ϵ, where",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 293,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 302,
      "text": "ϵ = 0.01 and the index i runs over the test samples.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 301,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 303,
      "text": "0 2 4 6 8 10Samples(×500)0.00.050.10.150.20.250.3TestMSE A 0 2 4 6 8 10Samples(×500)0.00.20.40.60.81.0TestAccuracy B CHLrCHLBPFDA",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 304,
      "text": "Figure 8: Exclusive OR (XOR). Four different learning algorithms have been use to train a feed-forward",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 303,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 305,
      "text": "network with three layers, L = 3, (2 − 2 − 1). (A) Test MSE error illustrated against the numb er of samples,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 304,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 306,
      "text": "(B) test accuracy. The red and purples lines indicate the CHL and rCHL, respectively. The brown and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 305,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 307,
      "text": "gray dashed lines show the minimum test MSE and the maximum test accuracy for the BP and the FDA,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 306,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 308,
      "text": "resp ectively.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 307,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 309,
      "text": "The results of the learning are shown in figure 8, where figure 8A shows the test error, and figure 8B the",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 301,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 310,
      "text": "test accuracy for CHL (red line) and rCHL (purple line). The test error and the test accuracy attained is the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 309,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 311,
      "text": "same for BP (brown dashed line) and FDA (gray dashed line). Comparing against the error and accuracy of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 310,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 312,
      "text": "BP and FDA (see SI figure 11), rCHL converges faster and more smoothly. This is because rCHL and CHL",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 311,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 313,
      "text": "are on-line learning algorithms, and the input and target signals are both embedded into the dynamics of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 312,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 314,
      "text": "the neurons. This leads to a rapid convergence of the Hebbian learning rule, which rapidly assimilates the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 313,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 315,
      "text": "prop er associations between input and output signals.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 314,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 316,
      "text": "3.3 Handwritten Digit and Letter Classification",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 292,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 317,
      "text": "For the classification tasks, we used the MNIST [7] dataset of 10 handwritten digits and the eMNIST",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 316,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 318,
      "text": "datasets [5] of 26 handwritten letters of the English alphab et. The neural network layouts for the MNIST",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 317,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 319,
      "text": "and the eMNIST was 784 − 128− 64 − 10 and 784 − 256 − 128 − 26, resp ectively. On every unit in b oth MNIST",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 318,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 320,
      "text": "and eMNIST networks, we use a sigmoid function: f (x) = (1 + exp(−x))−1 . We drew the initial synaptic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 319,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 321,
      "text": "weights and the random matrices from uniform distributions U (−0.6, 0.6) and U (−0.3, 0.3), resp ectively. We",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 320,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 322,
      "text": "trained the network for 20 (MNIST) and 40 (eMNIST) epo chs, and in each epoch we present the entire",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 321,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 323,
      "text": "MNIST and eMNIST datasets, which consist of 60, 000 and 124, 800 images, respectively. At the end of each",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 322,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 324,
      "text": "ep och, we measured the MSE and the accuracy of the network. The accuracy is defined to b e the ratio of the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 323,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 325,
      "text": "successfully classified images to the total presented test images (10, 000 for MNIST and 20, 800 for eMNIST,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 324,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 326,
      "text": "resp ectively). Figure 9A illustrates the test error of CHL (red line) and rCHL (purple line), resp ectively.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 325,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 327,
      "text": "The error is lower than BP and FDA (brown and gray dashed lines, respectively), and the convergence is",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 326,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 328,
      "text": "faster (compared against SI figure 12, where BP and FDA test MSE and accuracy are illustrated). However,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 327,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 329,
      "text": "the classification test accuracy is the same as for BP and FDA, as figure 9B indicates. The convergence of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 328,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 330,
      "text": "the BP and FDA algorithms can be seen in SI figure 12, as well as the test accuracy of those algorithms",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 329,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 331,
      "text": "performing on the same type of neural network (same neural units and network architecture).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 330,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 332,
      "text": "For the eMNIST dataset, the test error is illustrated in figure 9C, where the error of CHL (red line) and",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 317,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 333,
      "text": "rCHL (purple line) are close to the error attained by BP and FDA (brown and gray dashed lines). However,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 332,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 334,
      "text": "the classification test accuracy of rCHL is worse than the other three learning algorithms (CHL, BP and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 333,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 335,
      "text": "FDA), as figures 9D and SI 13 B show. For the eMNIST data set the accuracy of the rCHL is lower than",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 334,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 336,
      "text": "the other three algorithms despite the fact that the error is smaller than the errors of BP and FDA. This",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 335,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 337,
      "text": "drawback might be due to the feed-back random matrix and the lack of symmetric synaptic connections.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 336,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 338,
      "text": "11",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 339,
      "text": "0 2 5 7 10 12 15 17 20Samples(×50000)0.00.0050.010.0150.020.0250.03TestMSE A MNIST 0 2 5 7 10 12 15 17 20Samples(×50000)0.00.20.40.60.81.0TestAccuracy B MNIST CHLrCHLBPFDA0 5 10 15 20 25 30 35 40Samples (x120000)0.00.020.040.060.080.1TestMSE C eMNIST 0 5 10 15 20 25 30 35 40Samples (x120000)0.00.20.40.60.81.0TestAccuracy D eMNIST",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 340,
      "text": "Figure 9: MNIST and eMNIST digits classification. The figure illustrates (A) the test error and (B) the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 339,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 341,
      "text": "accuracy of a neural network (784 − 128 − 64 − 10) with sigmoid function as non-linearity in all layers. The",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 340,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 342,
      "text": "network was trained on the entire MNIST set of digits (50, 000 images) and tested on the whole MNIST test",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 341,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 343,
      "text": "set (10, 000 images). In addition, (C) illustrates the test error and (D) the accuracy of a neural network",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 342,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 344,
      "text": "(784 − 256 − 128 − 26) with sigmoid function as non-linearity in all layers. The network was trained on the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 343,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 345,
      "text": "entire eMNIST set of digits (124, 800 images) and tested on the whole eMNIST test set (20, 800 images). In",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 344,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 346,
      "text": "both cases the MNIST and the eMNIST, CHL and rCHL have similar performance (red and purple curves,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 345,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 347,
      "text": "resp ectively).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 346,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 348,
      "text": "12",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 349,
      "text": "This is also supp orted by the fact that the CHL (which differs from rCHL only in the way the feedback signals",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 332,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 350,
      "text": "are transmitted) achieves an accuracy as go od as the BP and FDA (minimum test error and maximum test",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 349,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 351,
      "text": "accuracy for all four algorithms are provided in table 5.2,Appendix 5.2).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 350,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 352,
      "text": "3.4 Autoenco der",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 316,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 353,
      "text": "The final test case was the implementation of an autoencoder using CHL and rCHL. An autoencoder is a",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 352,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 354,
      "text": "neural network that learns to reconstruct the input data using a restricted latent representation. Classic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 353,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 355,
      "text": "autoencoders consist of three layers: the first layer is called the encoder, which is responsible for enco ding",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 354,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 356,
      "text": "the input data to the hidden layer, which describ es a code. The third layer is the decoder, which generates",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 355,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 357,
      "text": "the approximation of the input data, based on the code provided by the hidden layer [12].",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 356,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 358,
      "text": "To this end, we use a network with three layers L = 3, with a layout 784 − 36 − 784, and we use the",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 353,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 359,
      "text": "MNIST handwritten digits. This means that we enco de the input images of dimension 784 to a dimension",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 358,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 360,
      "text": "of 36. For both CHL and rCHL, the learning rate is set to η = 0.05. The synaptic weights and the random",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 359,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 361,
      "text": "matrix G were initialized from uniform distributions U (−0.5, 0.5) and U (−1, 1), respectively. We trained the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 360,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 362,
      "text": "network for 20 epochs, and in each ep och we presented to the network 5, 000 samples of MNIST handwritten",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 361,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 363,
      "text": "digits.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 362,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 364,
      "text": "ABCD 4202 E 864202468",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 365,
      "text": "Figure 10: CHL and rCHL autoencoder. The MNIST dataset was used to train an autoencoder using CHL",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 364,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 366,
      "text": "and rCHL. (A) shows some randomly chosen MNIST digits. After training the network for 40 epochs (during",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 365,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 367,
      "text": "each epoch we presented 5, 000 MNIST images to the network), it was able to reconstruct the learned digits",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 366,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 368,
      "text": "as panel (B) shows for CHL, and panel (C) for rCHL. The learned representations are shown in panels (D)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 367,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 369,
      "text": "and (E) for CHL and rCHL, respectively.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 368,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 370,
      "text": "After training the autoenco der, we fed 9 digits (figure 10A) from the MNIST dataset to the autoencoders.",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 358,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 371,
      "text": "The decoding (reconstruction) of the input data is illustrated in figures 10B and 10C for CHL and rCHL,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 370,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 372,
      "text": "resp ectively. The results indicate that rCHL and its non-random counterpart (CHL), can both learn to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 371,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 373,
      "text": "approximate the identity function, and thus they are both go od candidates for implementing autoencoders.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 372,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 374,
      "text": "The reconstruction (decoding) was not p erfect, which implies that the network correctly learned an approxi-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 373,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 375,
      "text": "mation (and not the exact function), indicating that the network had learned the appropriate representations",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 374,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 376,
      "text": "(code). The representations (codebooks) are shown in figures 10D and 10E for the CHL and rCHL models,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 375,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 377,
      "text": "13",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 12,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 378,
      "text": "resp ectively. As expected, the representations of rCHL were more noisy than that of the CHL model. This",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 376,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 379,
      "text": "can b e partially explained by the chosen simulation parameters in this exp eriment.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 378,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 380,
      "text": "4 Discussion",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 149,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 381,
      "text": "In this work, we introduced a modified version of Contrastive Hebbian Learning [50, 31, 3], based on random",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 380,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 382,
      "text": "feedback connections. The key contribution of this work is a biologically plausible variant of CHL, attained",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 381,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 383,
      "text": "by using random fixed matrices (during learning) instead of bidirectional synapses. We have shown that this",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 382,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 384,
      "text": "new variation of CHL, random Contrastive Hebbian Learning, can achieve results equivalent to that of CHL,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 383,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 385,
      "text": "BP, or FDA. In addition, rCHL can solve logical problems such as the XOR, as well as classification tasks,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 384,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 386,
      "text": "such as the handwritten digits and letters classification (MNIST and eMNIST datasets). Furthermore, rCHL",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 385,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 387,
      "text": "supports representation learning (e.g., auto encoders), as well.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 386,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 388,
      "text": "We provide a thorough investigation of the algorithm, examining how the different parameters of the",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 381,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 389,
      "text": "learning scheme affect the learning process. We have shown that the feedback gain γ affects the p erformance",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 388,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 390,
      "text": "of learning. The smaller the gain γ, the b etter the p erformance of the algorithm, implying that the feedback",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 389,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 391,
      "text": "gain should be small. This is in accordance with previous theoretical results found in [50], where CHL",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 390,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 392,
      "text": "requires low values of γ in order to be equivalent to BP. A second factor that affects learning is the number",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 391,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 393,
      "text": "of hidden layers. When the number of hidden layers increases, the p erformance of the learning decreases.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 392,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 394,
      "text": "However, this can b e mitigated by increasing the feedback gain γ (see figure 5). Finally, we tested the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 393,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 395,
      "text": "initial conditions of the random matrix G. We found that if we choose the random matrix from a normal",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 394,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 396,
      "text": "distribution with zero mean, the convergence sp eed of the learning algorithm is faster than if we draw G",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 395,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 397,
      "text": "from a uniform distribution. In addition, the variance σ and the interval length λ of the normal and uniform",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 396,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 398,
      "text": "distributions, respectively, affect the learning as well. The smaller the values, the faster the convergence of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 397,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 399,
      "text": "the learning.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 398,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 400,
      "text": "We further investigated the feedback random matrices using to ols provided by the pseudosp ectra anal-",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 388,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 401,
      "text": "ysis [46, 49]. The convergence of learning can be affected by the choice of distribution that generates the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 400,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 402,
      "text": "feedback random matrix. We found that sub-Gaussian feedback matrices with normal-like pseudospectrum",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 401,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 403,
      "text": "tend to cause slower convergence of learning, but a more robust one. On the other hand, Gaussian random",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 402,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 404,
      "text": "matrices tend to have faster convergence.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 403,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 405,
      "text": "Both CHL and rCHL share some common prop erties such as (i) the neurons express non-linear dynamics,",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 400,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 406,
      "text": "(ii) the learning rule is based on Hebb’s rule [14], which means no biologically implausible information is",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 405,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 407,
      "text": "necessary (e.g., knowledge of the derivatives of the non-linearities of the neural units), (iii) the propagation",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 406,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 408,
      "text": "of the activity from one layer to the next takes place in a manner similar that of biological systems. All the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 407,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 409,
      "text": "layers are coupled through a non-linear dynamical system, which implies that when an input is presented",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 408,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 410,
      "text": "the algorithm does not have to wait until all the units in the k-th layer have fired. Instead, neurons can",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 409,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 411,
      "text": "propagate their activity through couplings to the next (k + 1)-th layer. This is not the case for artificial",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 410,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 412,
      "text": "neural networks where the activity is computed for all the units of the k -th layer prior to transmission to the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 411,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 413,
      "text": "subsequent layer. Thus, CHL and rCHL circulate signals in a more natural fashion (similar to the processes",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 412,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 414,
      "text": "evident in biological nervous systems).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 413,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 415,
      "text": "The salient difference b etween CHL and rCHL is the replacement of symmetric synaptic weights (CHL)",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 405,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 416,
      "text": "with fixed random matrices (rCHL). Therefore, the feedback connections do not require any symmetric",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 415,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 417,
      "text": "weights (transp ose matrices) of the feed-forward connections. This is in accordance with biology since there",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 416,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 418,
      "text": "is no evidence thus far to indicate that chemical synapses (one of the two ma jor synapse types in the nervous",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 417,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 419,
      "text": "system, the other being electrical synapses) are bidirectional [17, 40]. More precisely, we can interpret the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 418,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 420,
      "text": "random feedback as a mo del of afferent feedback connections from higher hierarchical layers to lower ones.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 419,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 421,
      "text": "For instance, primary sensory areas are connected in series with higher sensory or multi-modal areas. These",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 420,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 422,
      "text": "higher areas pro ject back to the primary areas through feedback pathways [26, 36, 11]. Other typ es of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 421,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 423,
      "text": "feedback pathways to which our approach may be considered relevant are the inter-laminar connections",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 422,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 424,
      "text": "within cortical layers [13, 45]. Therefore, such feedback pathways can b e modeled as random feedback",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 423,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 425,
      "text": "matrices that interfere with the neural dynamics of the lower layers (top-down signal transmission). The",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 424,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 426,
      "text": "randomness in these feedback pathways can account for currently unknown underlying neural dynamics or",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 425,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 427,
      "text": "14",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 13,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 428,
      "text": "random networks with interesting properties [29, 48].",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 426,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 429,
      "text": "Our current implementation, rCHL, allows us to interpret the backward phase (clamped) as a top-down",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 415,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 430,
      "text": "signal propagation. For instance, when a visual stimulus is presented, such as a letter, and a sub ject is",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 429,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 431,
      "text": "required to learn the semantic of the letter (which letter is presented), then the target can be the semantic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 430,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 432,
      "text": "and the input signal the image of the letter. Therefore, we can assume that the forward phase simulates",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 431,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 433,
      "text": "the bottom-up signal propagation from the primary sensory cortices to higher associate cortices, and the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 432,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 434,
      "text": "backward phase as the top-down signal propagation from the higher cognitive areas back to the lower cortical",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 433,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 435,
      "text": "areas.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 434,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 436,
      "text": "Due to the nature of the learning algorithm and the two phases (positive and negative), the input and",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 429,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 437,
      "text": "the target signals are clamped, and the dynamics of those signals are captured and embedded in the neural",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 436,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 438,
      "text": "dynamics of the network. This can b e compared to target propagation [21, 19], where the loss gradient of BP",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 437,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 439,
      "text": "is replaced by a target value. When the target value is very close to the neural activation of the forward pass,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 438,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 440,
      "text": "TP b ehaves like BP. These sort of learning algorithms solve the credit assignment problem [30], using local",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 439,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 441,
      "text": "information. In the proposed mo del, the target and the input signals are both embedded into the dynamics",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 440,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 442,
      "text": "of the neural activity and affect the learning pro cess in an indirect way through a Hebb and an anti-Hebb",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 441,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 443,
      "text": "rule.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 442,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 444,
      "text": "The major contribution of this work is the development of a new method to implement CHL using",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 436,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 445,
      "text": "random feedback instead of symmetric one. This leads to a more biologically plausible implementation of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 444,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 446,
      "text": "CHL without loss of performance and accuracy in most of the cases studied. In addition, the algorithm offers",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 445,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 447,
      "text": "a shorter runtime since it does not require the computation of the transpose matrix for synaptic weights at",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 446,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 448,
      "text": "every time step. Furthermore, the proposed algorithm offers a suitable learning scheme for neuromorphic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 447,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 449,
      "text": "devices since its neural dynamics can be transformed into spiking neurons [10]. Therefore, we can build",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 448,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 450,
      "text": "spiking neural networks with STDP-like learning rules as equivalent to the Hebb’s rule in rCHL and use ideas",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 449,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 451,
      "text": "from event-based Contrastive Divergence [32] and synaptic sampling machines [34] in order to implement a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 450,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 452,
      "text": "neuromorphic rCHL. This idea is similar to the event-based random back-propagation algorithm [33], where",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 451,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 453,
      "text": "the authors have implemented an event-based feedback alignment equivalent for neuromorphic devices.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 452,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 454,
      "text": "A potential extension of the model might be a replacement of the firing rate units with spiking neurons,",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 444,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 455,
      "text": "such as leaky integrate-and-fire units, in order to make the computations even more similar to the biological",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 454,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 456,
      "text": "case. Another potential direction would be to remove entirely the synchronization in the neural dynamics",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 455,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 457,
      "text": "integration. This means that the integrations of neural dynamics can take place on-demand in a more event-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 456,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 458,
      "text": "based fashion [41, 44]. Since the units are coupled with each other, and the propagation of activity takes",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 457,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 459,
      "text": "place in a more natural way, we might be able to use asynchronous algorithms for implementing rCHL such",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 458,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 460,
      "text": "that it scales up in a more efficient and natural way. Another extension of the mo del in the future would be",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 459,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 461,
      "text": "to impose sparsity constraints on the learning rule in order to render data encoding processes more efficient.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 460,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 462,
      "text": "Furthermore, such a mo dification would make the model able to simulate more biological phenomena, such",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 461,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 463,
      "text": "as the sparse compression occurring within the hippocampus [39].",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 462,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 464,
      "text": "In the future, we would like to conduct more analytical work to determine the optimal typ e of random",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 454,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 465,
      "text": "matrix G, for a given problem, and how to design such a matrix, if it does exist. This means that if",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 464,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 466,
      "text": "an optimal random matrix G exists, then one can prop erly cho ose the eigenvalues (or singular values)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 465,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 467,
      "text": "and the distribution that generates that matrix based on the problem they would like to solve. To this",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 466,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 468,
      "text": "end, the pseudospectra analysis can play a key role. Pseudosp ectra can help us to better understand the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 467,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 469,
      "text": "relations between singular values, convergence of learning and accuracy. This can lead to the development",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 468,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 470,
      "text": "of sophisticated metho ds for designing feedback matrices with particular properties. Therefore, we could",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 469,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 471,
      "text": "improve and accelerate the learning process.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 470,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 472,
      "text": "Author Contributions",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 380,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 473,
      "text": "GD conceived the idea, implemented CHL and rCHL, ran the CHL and rCHL experiments; TB implemented",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 472,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 474,
      "text": "and ran the BP and FDA experiments; GD analyzed and interpreted the results; All the authors wrote and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 473,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 475,
      "text": "reviewed the manuscript.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 474,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 476,
      "text": "15",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 14,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 477,
      "text": "Acknowledgments",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 472,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 478,
      "text": "This work was supported in part by the Intel Corporation and by the National Science Foundation under",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 477,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 479,
      "text": "grant 1640081. We thank NVIDIA corporation for providing the GPU used in this work.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 478,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 480,
      "text": "5 Appendix",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 380,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 481,
      "text": "5.1 Λϵ-pseudospectra",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 480,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 482,
      "text": "Let V ∈ Rm×n be a rectangular matrix, not necessarily normal (i.e., VV ∗ ̸= V∗V). The ϵ-pseudospectra",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 481,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 483,
      "text": "(Λϵ) [47, 49] is the set of ϵ-eigenvalues a closed subset of C.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 482,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 484,
      "text": "Definition 5.1 (ϵ-Pseudospectra). Let V ∈ C or R, z ∈ C and ˜I ∈ Rm×n (the identity matrix with",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 483,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 485,
      "text": "ones on the main diagonal and zeros elsewhere), then the ϵ-pseudospectra Λϵ = {z ∈ C : ||(V − z˜I)υυυ|| ≤",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 484,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 486,
      "text": "ϵ for some υυυ ∈ Cn , ||υυυ|| = 1}.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 485,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 487,
      "text": "Definition 5.2 (ϵ-Pseudospectra). Let V ∈ C or R, z ∈ C and ˜I ∈ Rm×n (the identity matrix with ones on",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 482,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 488,
      "text": "the main diagonal and zeros elsewhere), then the ϵ-pseudosp ectra Λϵ = {z ∈ C : σmin (z˜I − V) ≤ ϵ}.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 487,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 489,
      "text": "Definitions 5.1 and 5.2 are equivalent [49], and b oth account for the computation of Λϵ of rectangular",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 487,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 490,
      "text": "matrices of dimension m × n, where m ≥ n. The algorithm given in [49] for the numerical computation of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 489,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 491,
      "text": "the set Λϵ can be applied on matrices of dimension m × n, where either m ≥ 2n or m ≤ 2n.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 490,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 492,
      "text": "5.2 Error and Accuracy Table",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 481,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 493,
      "text": "Here we provide the minimum test error and maximum test accuracy for each of the exp eriments (XOR,",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 492,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 494,
      "text": "MNIST and eMNIST). We compare in the following table our CHL and rCHL implementations against each",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 493,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 495,
      "text": "other and against the BP and the FDA.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 494,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 496,
      "text": "AlgorithmExp eriment XOR MNIST eMNISTBP 0.003/1 0.0087/0.962 0.0116/0.8935FDA 0.0009/1 0.0066/0.969 0.0087/0.9035CHL 2.503e−8/1 0.0038/0.977 0.0061/0.899rCHL 1.117e−6/1 0.0044/0.975 0.0073/0.8461",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 497,
      "text": "Table 1: Mean squared error (MSE) and Accuracy. The test MSE and accuracy of three experiments,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 496,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 498,
      "text": "XOR, MNIST, and eMNIST are given in this table. BP–Backpropagation, FDA–Feedback Alignment, CHL–",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 497,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 499,
      "text": "Contrastive Hebbian Learning, and rCHL–random Contrastive Hebbian Learning.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 498,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 500,
      "text": "5.3 Abbreviations and Notation Tables",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 492,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 501,
      "text": "Abbreviation DescriptionSTDP Spike-timing Dep endent PlasticityBP Back-propagationFDA Feedback AlignmentCHL Contrastive Hebbian LearningrCHL random Contrastive Hebbian LearningMSE Mean Squared Error",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 502,
      "text": "Table 2: Abbreviations",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 501,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 503,
      "text": "16",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 15,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 504,
      "text": "Symbols DescriptionL Total number of layersk Index of layerxk Neural state at layer kˇxk Neural state at layer k in the free phaseˆxk Neural state at layer k in the clamped phaseWk Synaptic matrix (connects layer k − 1 with k )Gk Random feedback matrix (connects layer k − 1 with kbk Bias for layer kfk Non-linear function (transfer function)η Learning rateγ Feedback gain⊗ Tensor productdt Forward Euler time-steptf Forward Euler total integration timeI Input data setT Target setΛϵ Set of pseudosp ectraλ EigenvalueU Uniform distributionℓ Length of uniform’s distribution intervalN Normal distributionσ Normal distribution’s variance⊕ Exclusive Or (XOR)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 16,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 505,
      "text": "Table 3: Notation",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 504,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 16,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 506,
      "text": "17",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 3,
      "rel_name": "meta",
      "page_id": 16,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 507,
      "text": "5.4 Simulation and Platform Details",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 500,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 17,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 508,
      "text": "All serial simulations were run on a Dell OptiPlex 7040 with 16GB physical memory, and a 6th generation",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 507,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 17,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 509,
      "text": "Intel i7 processor (Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz) running Arch Linux (4.11.9 − 1-ARCH",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 508,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 17,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 510,
      "text": "×86 64 GNU/Linux). The source code for CHL and rCHL were written in the C programming language [18]",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 509,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 17,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 511,
      "text": "(gcc (GCC) 7.1.120170630). In all C simulations, we used the random numb er generator provided by [37]2 .",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 510,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 17,
      "box": [
        0,
        0,
        0,
        0
      ]
    }
  ]
}