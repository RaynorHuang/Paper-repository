{
  "doc_id": "1712.08207",
  "nodes": [
    {
      "id": 0,
      "text": "1 INTRODUCTION",
      "label_id": 0,
      "label_name": "Title",
      "is_meta": true,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 1,
      "text": "Variational Attention for Sequence-to-Sequence Models",
      "label_id": 0,
      "label_name": "Title",
      "is_meta": true,
      "parent": 0,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 2,
      "text": "Hareesh Bahuleyan∗ † Lili Mou∗‡ Olga Vechtomova† Pascal Poupart†",
      "label_id": 1,
      "label_name": "Author",
      "is_meta": true,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 3,
      "text": "† University of Waterloo, Canada",
      "label_id": 1,
      "label_name": "Author",
      "is_meta": true,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 4,
      "text": "{hpallika, ovechtomova, ppoupart}@uwaterloo.ca",
      "label_id": 3,
      "label_name": "Affiliation",
      "is_meta": true,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 5,
      "text": "‡ AdeptMind Research, Toronto, Canada",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 6,
      "text": "doublepower.mou@gmail.com",
      "label_id": 3,
      "label_name": "Affiliation",
      "is_meta": true,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 7,
      "text": "Abstract",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 8,
      "text": "The variational encoder-decoder (VED) encodes source information as a set of random variables",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 7,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 9,
      "text": "using a neural network, which in turn is decoded into target data using another neural network. In",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 8,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 10,
      "text": "natural language processing, sequence-to-sequence (Seq2Seq) models typically serve as encoder-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 9,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 11,
      "text": "decoder networks. When combined with a traditional (deterministic) attention mechanism, the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 10,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 12,
      "text": "variational latent space may be bypassed by the attention model, and thus becomes ineffective.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 11,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 13,
      "text": "In this paper, we propose a variational attention mechanism for VED, where the attention vector",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 12,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 14,
      "text": "is also modeled as Gaussian distributed random variables. Results on two experiments show that,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 13,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 15,
      "text": "without loss of quality, our proposed method alleviates the bypassing phenomenon as it increases",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 14,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 16,
      "text": "the diversity of generated sentences.1",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 7,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 17,
      "text": "1 Introduction",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 7,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 18,
      "text": "The variational autoencoder (VAE), proposed by Kingma and Welling (2014), encodes data to latent (ran-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 17,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 19,
      "text": "dom) variables, and then decodes the latent variables to reconstruct the input data. Theoretically, it opti-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 18,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 20,
      "text": "mizes a variational lower bound of the log-likelihood of the data. Compared with traditional variational",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 19,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 21,
      "text": "methods such as mean-field approximation (Wainwright et al., 2008), VAE leverages modern neural net-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 20,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 22,
      "text": "works and hence is a more powerful density estimator. Compared with traditional autoencoders (Hinton",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 21,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 23,
      "text": "and Salakhutdinov, 2006), which are deterministic, VAE populates hidden representations to a region (in-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 22,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 24,
      "text": "stead of a single point), making it possible to generate diversified data from the vector space (Bowman",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 23,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 25,
      "text": "et al., 2016) or even control the generated samples (Hu et al., 2017).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 24,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 26,
      "text": "In natural language processing (NLP), recurrent neural networks (RNNs) are typically used as both the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 18,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 27,
      "text": "encoder and decoder, known as a sequence-to-sequence (Seq2Seq) model. Although variational Seq2Seq",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 26,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 28,
      "text": "models are much trickier to train in comparison to the image domain, Bowman et al. (2016) succeed in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 27,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 29,
      "text": "training a sequence-to-sequence VAE and generating sentences from a continuous latent space. Such an",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 28,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 30,
      "text": "architecture can further be extended to a variational encoder-decoder (VED) to transform one sequence",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 29,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 31,
      "text": "into another with the “variational” property (Serban et al., 2017; Zhou and Neubig, 2017).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 30,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 32,
      "text": "When applying attention mechanisms (Bahdanau et al., 2015) to variational Seq2Seq models, however,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 26,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 33,
      "text": "we find the generated sentences are of less variety, implying that the variational latent space is ineffec-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 32,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 34,
      "text": "tive. The attention mechanism summarizes source information as an attention vector by weighted sum,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 33,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 35,
      "text": "where the weights are a learned probabilistic distribution; then the attention vector is fed to the decoder.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 34,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 36,
      "text": "Evidence shows that attention significantly improves Seq2Seq performance in translation (Bahdanau et",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 35,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 37,
      "text": "al., 2015), summarization (Rush et al., 2015), etc. In variational Seq2Seq, however, the attention mecha-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 36,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 38,
      "text": "nism unfortunately serves as a “bypassing” mechanism. In other words, the variational latent space does",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 37,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 39,
      "text": "not need to learn much, as long as the attention mechanism itself is powerful enough to capture source",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 38,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 40,
      "text": "information.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 39,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 41,
      "text": "The first two authors contributed equally.",
      "label_id": 13,
      "label_name": "Footnote",
      "is_meta": true,
      "parent": 32,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 42,
      "text": "Code is available at https://github.com/HareeshBahuleyan/tf-var-attention",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": 41,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 43,
      "text": "This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:",
      "label_id": 13,
      "label_name": "Footnote",
      "is_meta": true,
      "parent": 42,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 44,
      "text": "//creativecommons.org/licenses/by/4.0/",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": 43,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 45,
      "text": "In Proceedings of COLING 2018. Also accepted by TADGM Workshop@ICML 2018 for presentation.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": 43,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 0,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 46,
      "text": "In this paper, we propose a variational attention mechanism to address this problem. We model the",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 45,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 47,
      "text": "attention vector as random variables by imposing a probabilistic distribution. We follow traditional VAE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 46,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 48,
      "text": "and model the prior of the attention vector by a Gaussian distribution, for which we further propose two",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 47,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 49,
      "text": "plausible priors, whose mean is either a zero vector or an average of source hidden states.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 48,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 50,
      "text": "We evaluate our approach on two experiments: question generation and dialog systems. Experiments",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 46,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 51,
      "text": "show that the proposed variational attention yields a higher diversity than variational Seq2Seq with de-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 50,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 52,
      "text": "terministic attention, while retaining high quality of generated sentences. In this way, we make VED",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 51,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 53,
      "text": "work properly with the powerful attention mechanism.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 52,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 54,
      "text": "In summary, the main contributions of this paper are two-fold: (1) We discover a “bypassing” phe-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 50,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 55,
      "text": "nomenon in VED, which could make the learning of variational space ineffective. (2) We propose a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 54,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 56,
      "text": "variational attention mechanism that models the attention vector as random variables to alleviate the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 55,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 57,
      "text": "above problem. To the best of our knowledge, we are the first to address the attention mechanism in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 56,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 58,
      "text": "variational encoder-decoder neural networks. Our model is a general framework, which can be applied",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 57,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 59,
      "text": "for various text generation tasks.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 58,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 60,
      "text": "2 Background and Motivation",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 17,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 61,
      "text": "In this section, we introduce the variational autoencoder and the attention mechanism. We also present a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 60,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 62,
      "text": "pilot experiment motivating our variational attention model.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 61,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 63,
      "text": "2.1 Variational Autoencoder (VAE)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 60,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 64,
      "text": "A VAE encodes data Y (e.g., a sentence) as hidden random variables Z, based on which the decoder",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 63,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 65,
      "text": "reconstructs Y . Consider a generative model, parameterized by θ, as",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 64,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 66,
      "text": "pθ (Z, Y ) = pθ (Z )pθ (Y |Z) (1)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 65,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 67,
      "text": "Given a dataset D = {y (n) }Nn=1 , the likelihood of a data point is",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 66,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 68,
      "text": "log pθ(y(n) ) ≥ Ez ∼qϕ (z|y (n) ) (cid:34) log (cid:40) pθ(y(n) , z) qϕ (z|y(n)) (cid:41)(cid:35) = Ez∼qϕ(z |y(n)) (cid:104) log pθ (y(n)|z ) (cid:105) − KL (cid:16) qϕ (z|y(n))∥p(z) (cid:17) ∆ = L(n)(θ, ϕ) (2)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 67,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 69,
      "text": "VAE models both qϕ (z |y ) and pθ (y|z ) with neural networks, parametrized by ϕ and θ, respectively.",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 66,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 70,
      "text": "Figure 1a shows the graphical model of this process. The training objective is to maximize the lower",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 69,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 71,
      "text": "bound of the likelihood L(θ, ϕ), which can be rewritten as minimizing",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 70,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 72,
      "text": "J (n) = Jrec(θ, ϕ, y(n) ) + KL (cid:16) qϕ (z|y(n))∥p(z) (cid:17) (3)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 71,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 73,
      "text": "The first term, called reconstruction loss, is the (expected) negative log-likelihood of data, similar to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 72,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 74,
      "text": "traditional deterministic autoencoders. The expectation is obtained by Monte Carlo sampling. The sec-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 73,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 75,
      "text": "ond term is the KL-divergence between z’s posterior and prior distributions. Typically the prior is set to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 74,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 76,
      "text": "standard normal N (0, I).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 75,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 77,
      "text": "2.2 Variational Encoder-Decoder (VED)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 63,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 78,
      "text": "In some applications, we would like to transform source information to target information, e.g., machine",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 77,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 79,
      "text": "translation, dialogue systems, and text summarization. In these tasks, “auto”-encoding is not sufficient,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 78,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 80,
      "text": "and an encoding-decoding framework is required. Different efforts have been made to extend VAE to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 79,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 81,
      "text": "variational encoder-decoder (VED) frameworks, which transform an input X to output Y . One possible",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 80,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 82,
      "text": "extension is to condition all probabilistic distributions further on X (Zhang et al., 2016; Cao and Clark,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 81,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 1,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 83,
      "text": "IMAGE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 84,
      "text": "Figure 1: Graphical model representations. (a) Variational autoencoder (VAE). (b) Variational encoder-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 83,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 85,
      "text": "decoder (VED). (c) VED with deterministic attention (VED+DAttn). (d) VED with variational attention",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 84,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 86,
      "text": "(VED+VAttn). Dashed lines: Encoding phase. Solid lines: Decoding phase.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 85,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 87,
      "text": "Input: the men are playing musical instruments(a) VAE w/o hidden state init. (Avg entropy: 2.52) (b) VAE w/ hidden state init. (Avg entropy: 2.01)the men are playing musical instruments the men are playing musical instrumentsthe men are playing video games the men are playing musical instrumentsthe musicians are playing musical instruments the men are playing musical instrumentsthe women are playing musical instruments the man is playing musical instruments",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 86,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 88,
      "text": "Table 1: Sentences obtained by sampling from the VAE’s latent space. (a) VAE without hidden state",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 87,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 89,
      "text": "initialization. (b) VAE with hidden state initialization.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 88,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 90,
      "text": "2017; Serban et al., 2017). In this case, the posterior of z is given by qϕ (z |X , Y ). This, however,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 78,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 91,
      "text": "introduces a discrepancy between training and prediction, since Y is not available during the prediction",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 90,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 92,
      "text": "stage.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 91,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 93,
      "text": "Another approach is to build a recognition model using only X (Zhou and Neubig, 2017). Making the",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 90,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 94,
      "text": "= qϕ(z |x). assumption that Y is a function of X , i.e., Y = Y (X ), we have qϕ(z|y) = qϕ(z|Y (x))",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 93,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 95,
      "text": "In this work, we follow Zhou and Neubig (2017) and adopt this extension. Figure 1b shows the graphical",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 94,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 96,
      "text": "model of the VED used in our work.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 95,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 97,
      "text": "2.3 Seq2Seq and Attention Mechanism",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 63,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 98,
      "text": "In NLP, sequence-to-sequence recurrent neural networks are typically used as the encoder and decoder,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 97,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 99,
      "text": "as they are suitable for modeling a sequence of words (i.e., sentence). Figure 2a shows a basic Seq2Seq",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 98,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 100,
      "text": "model in the VAE/VED scenario (Bowman et al., 2016). The encoder has an input x, and outputs µz and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 99,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 101,
      "text": "σz as the parameters of z’s posterior normal distribution. Then a decoder generates y based on a sample",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 100,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 102,
      "text": "z, drawn from its posterior distribution.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 101,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 103,
      "text": "Attention mechanisms are proposed to dynamically align y = (y1, · · · , y|y|) and x = (x1 , · · · , x|x| )",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 98,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 104,
      "text": "during generation. At each time step j in the decoder, the attention mechanism computes a probabilistic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 103,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 105,
      "text": "distribution by",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 104,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 106,
      "text": "αji = exp{ (cid:101)αj i} (cid:80)|x| i′=1 exp{(cid:101)αj i′ } (4)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 105,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 107,
      "text": "where (cid:101)αji is a pre-normalized score, computed by (cid:101)αji = h(tar)j W T h(src)i in our model. Here, h(tar)j and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 106,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 108,
      "text": "h(src)i are the hidden representations of the jth step in target and ith in the source, and W is a learnable",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 107,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 109,
      "text": "weight matrix.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 108,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 110,
      "text": "Then the source information {h(src)i }|x|i=1 is summed by weights αji to obtain the attention vector",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 109,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 111,
      "text": "aj = |x| (cid:88) i=1 αj i h(src)i (5)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 110,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 112,
      "text": "which is fed to the decoder RNN at the j th step. Figure 2b shows the variational Seq2Seq model with",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 111,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 113,
      "text": "such traditional attention.",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 112,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 2,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 114,
      "text": "IMAGE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 115,
      "text": "Figure 2: (a) Variational Seq2Seq model. (b) Variational Seq2Seq with deterministic attention. (c)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 114,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 116,
      "text": "Variational Seq2Seq with hidden state initialization. (d) Variational Seq2Seq with variational attention.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 115,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 117,
      "text": "2.4 “Bypassing” Phenomenon",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 116,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 118,
      "text": "In this part, we explain the “bypassing” phenomenon in VAE/VED, if the network is not designed prop-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 117,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 119,
      "text": "erly; this motivates our variational attention described in Section 3.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 118,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 120,
      "text": "We observe that, if the decoder has a direct, deterministic access to the source, the latent variables Z",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 118,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 121,
      "text": "might not capture much information so that the VAE or VED does not play a role in the process. We call",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 120,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 122,
      "text": "this a bypassing phenomenon.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 121,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 123,
      "text": "Theoretically, if pθ(Y |·) is aware of X by itself, i.e., pθ (Y |·) becomes pθ (Y |X , Z), it could be",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 120,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 124,
      "text": "learned as pθ (Y |X ) without hurting the reconstruction loss Jrec, but the KL term in Eq. (3) can be min-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 123,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 125,
      "text": "imized by fitting the posterior to its prior. This degrades a variational Seq2Seq model to a deterministic",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 124,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 126,
      "text": "one.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 125,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 127,
      "text": "The phenomenon can be best shown with a bypassing connection between the encoder and decoder",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 123,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 128,
      "text": "for hidden state initialization. Some previous studies using VEDs set the decoder’s initial state to be",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 127,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 129,
      "text": "the encoder’s final state (Cao and Clark, 2017), shown in Figure 2c. We conducted a pilot study with a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 128,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 130,
      "text": "Seq2Seq VAE with a subset (∼80k samples) of the massive dataset provided by Bowman et al. (2015),",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 129,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 131,
      "text": "and show generated sentences and entropy in Table 1. We see that the variational Seq2Seq can only",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 130,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 132,
      "text": "generate very similar sentences with such bypassing connections (Table 1b), as opposed to generating",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 131,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 133,
      "text": "diversified samples from the latent space (Table 1a). We also computed the entropy for 10 randomly",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 132,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 134,
      "text": "sampled outputs for a given input sentence. Quantitatively, the entropy decreases by 0.5 on average for",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 133,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 135,
      "text": "1k unseen input sentences. This shows a significant difference because entropy is a logarithmic metric.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 134,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 136,
      "text": "Our analysis sheds light on the design philosophy of neural architectures in VAE or VED.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 135,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 137,
      "text": "Since attention largely improves model performance for deterministic Seq2Seq models, it is tempting",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 127,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 138,
      "text": "to include attention in the variational Seq2Seq as well. However, our pilot experiment raises the doubt",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 137,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 139,
      "text": "if a traditional attention mechanism, which is deterministic, may bypass the latent space in VED, as",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 138,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 140,
      "text": "illustrated by a graphical model in Figure 1c. Also, evidence in Zheng et al. (2018) shows the attention",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 139,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 141,
      "text": "mechanism is so powerful that removing other connections between the encoder and decoder has little",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 140,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 142,
      "text": "effect on BLEU scores in machine translation. Therefore, a VED with deterministic attention might learn",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 141,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 143,
      "text": "reconstruction mostly from attention, whereas the posterior of the latent space can fit to its prior in order",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 142,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 144,
      "text": "to minimize the KL term.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 143,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 145,
      "text": "To alleviate this problem, we propose a variational attention mechanism for variational Seq2Seq mod-",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 137,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 146,
      "text": "els, as is described in detail in the next section.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 145,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 3,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 147,
      "text": "3 The Proposed Variational Attention",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 146,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 148,
      "text": "Let us consider the decoding process of an RNN. At each timestep j, it adjusts its hidden state h(tar)j with",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 147,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 149,
      "text": "an input of a word embedding yj −1 (typically the groundtruth during training and the prediction from",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 148,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 150,
      "text": "the previous step during testing). This is given by h(tar)j = RNNθ (h(tar)j−1, yj−1 ). In our experiments, we",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 149,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 151,
      "text": "use long short-term memory units (Hochreiter and Schmidhuber, 1997) as RNN’s transition. Enhanced",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 150,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 152,
      "text": "with attention, the RNN is computed by h(tar)j = RNNθ (h(tar)j −1 , [yj−1; aj ]). The predicted word is given",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 151,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 153,
      "text": "by a softmax layer p(yj ) = softmax(Wouth(tar)j ), where Wout is a weight matrix. As discussed earlier,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 152,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 154,
      "text": "traditional attention computes aj in a deterministic fashion by Eq. (5).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 153,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 155,
      "text": "To build a variational attention, we treat both the traditional latent space z and the attention vector aj",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 148,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 156,
      "text": "as random variables. The recognition and reconstruction graphical models are shown in Figure 1d.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 155,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 157,
      "text": "3.1 Lower Bound",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 147,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 158,
      "text": "Since the likelihood of the nth data point decomposes for different time steps, we consider the lower",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 157,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 159,
      "text": "bound L(n)j (θ, ϕ) at the jth step. The variational lower bound in Eq. (2) becomes",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 158,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 160,
      "text": "L(n)j (θ , ϕ) = Ez,a∼qϕ(z,a|x(n) ) (cid:104)log pθ (y (n) |z, a)(cid:105) − KL (cid:16)qϕ (z , a|x(n) )∥p(z , a)(cid:17) (6)= Ez∼q(z )ϕ (z|x(n)),a∼q(a)ϕ (a|x(n) ) (cid:104)log pθ(y(n) |z, a)(cid:105)− KL (cid:16)q(z)ϕ (z|x(n) )∥p(z )(cid:17) − KL (cid:16)q (a)ϕ (a|x(n) )∥p(a)(cid:17) (7)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 159,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 161,
      "text": "Eq. (7) is due to the independence in both recognition and reconstruction phrases. The posterior factor-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 158,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 162,
      "text": "izes as qϕ(z , a|·) = q(z)ϕ (z|·) q (a)ϕ (a|·) because z and a are conditionally independent given x (dashed",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 161,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 163,
      "text": "lines in Figure 1d), whereas the prior factorizes because z and a are marginally independent (solid lines",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 162,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 164,
      "text": "in Figure 1d). In this way, the sampling procedure can be done separately and the KL loss can also be",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 163,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 165,
      "text": "computed independently.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 164,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 166,
      "text": "3.2 Prior",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 157,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 167,
      "text": "We propose two plausible prior distributions for aj .",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 166,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 168,
      "text": "• The simplest prior, perhaps, is the standard normal, i.e., p(aj ) = N (0, I). This follows the prior",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 167,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 169,
      "text": "of the latent space z as in a conventional autoencoder (Kingma and Welling, 2014; Bowman et al.,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 168,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 170,
      "text": "2016).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 169,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 171,
      "text": "• We observe that the attention vector has to be inside the convex hull of hidden representations of the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 168,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 172,
      "text": "source sequence, i.e., aj ∈ conv{h(src)i }. We impose a normal prior whose mean is the average of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 171,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 173,
      "text": "h(src)i , i.e., p(aj ) = N (¯h(src) , I), where ¯h(src) = 1|x| (cid:80)|x|i=1 h(src)i , making the prior non-informative.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 172,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 174,
      "text": "3.3 Posterior",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 173,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 175,
      "text": "We model the posterior of q (a)ϕ (aj |x) as a normal distribution N (µaj , σaj ), where the parameters µaj",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 174,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 176,
      "text": "and σaj are obtained by a recognition neural network. Similar to VAEs, we compute parameters as if in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 175,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 177,
      "text": "the deterministic attention in Eq. (5) (denoted by adetj in this part) and then transform them by another",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 176,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 178,
      "text": "layer, shown in Figure 2d.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 177,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 179,
      "text": "For the mean µaj , we apply an identity transformation, i.e., µaj ≡ adetj . The identify transformation",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 171,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 180,
      "text": "makes much sense as it preserves the spirit of “attention.” To compute σaj , we first transform adetj by a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 179,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 181,
      "text": "neural layer with tanh activation. The resulting vector then undergoes a linear transformation followed",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 180,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 182,
      "text": "by an exp activation function to ensure that the values are positive.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 181,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 183,
      "text": "3.4 Training Objective",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 167,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 4,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 184,
      "text": "(a) (b) (c) (d)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 185,
      "text": "Figure 3: Geometric interpretation of attention mechanisms.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 184,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 186,
      "text": "The overall training objective of Seq2Seq with both variational latent space z and variational attention a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 184,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 187,
      "text": "is to minimize",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 186,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 188,
      "text": "J (n)(θ, ϕ) = Jrec (θ, ϕ, y (n) ) + λKL(cid:104)KL (cid:16)q(z )ϕ (z|x(n) )∥p(z )(cid:17) + γa |y | (cid:88) j =1 KL (cid:16) q (a)ϕ (aj |x(n))∥p(aj )(cid:17) (cid:105) (8)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 187,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 189,
      "text": "Here, we have a hyperparameter λKL to balance the reconstruction loss and KL losses. γa further",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 188,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 190,
      "text": "balances the attention’s KL loss and z’s KL loss. Since VAE and VED are tricky with Seq2Seq models",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 189,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 191,
      "text": "(e.g., requiring KL annealing), we tie the change of both KL terms and only anneal λKL. (Training",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 190,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 192,
      "text": "details will be presented in Section 4.1.)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 191,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 193,
      "text": "Notice that if aj has a prior of N (¯h(src), I), the derivative of the KL term also goes to ¯h(src). This can",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 189,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 194,
      "text": "be computed straightforwardly or by auto-differentiation tools, e.g., TensorFlow.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 193,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 195,
      "text": "3.5 Geometric Interpretation",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 183,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 196,
      "text": "We present a geometric interpretation of both deterministic and variational attention mechanisms in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 195,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 197,
      "text": "Figure 3.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 196,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 198,
      "text": "Suppose the hidden representations h(src)i is of k-dimensional space (represented as a 3-d space in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 196,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 199,
      "text": "Figure 3). In the deterministic mechanism, the attention model is a convex combination of {h(src)i }|x|i=1,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 198,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 200,
      "text": "as the weights in Eq. (5) are a probabilistic distribution. The attention vector aj is a point in the convex",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 199,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 201,
      "text": "hull conv{h(src)i }, shown in Figure 3a.",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 200,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 202,
      "text": "For variational attention in Figures 3b and 3c, the mean of posterior is still in the convex hull, but",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 198,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 203,
      "text": "the sample drawn from the posterior is populated over the entire space (although mostly around the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 202,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 204,
      "text": "mean, shown as a ball). The difference between the two variants is that the standard normal prior",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 203,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 205,
      "text": "N (0, I) pulls the posterior to the origin, whereas the prior N ( ¯h(src) , I) pulls the posterior to the mean of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 204,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 206,
      "text": "h(src)1 , h(src)2 , · · · , h(src)|x| (indicated by red arrows).",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 205,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 207,
      "text": "Finally we would like to present a (potential) alternative of modeling variational attention. Instead of",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 202,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 208,
      "text": "treating aj as random variables, we might also treat αj as random variables. Since αj is the parameter",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 207,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 209,
      "text": "of a categorical distribution, its conjugate prior is a Dirichlet distribution. In this case, the resulting",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 208,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 210,
      "text": "attention vector populates the entire convex hull (Figure 3d). However, it relies on a reparametrization",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 209,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 211,
      "text": "trick to propagate reconstruction error’s gradient back to the recognition neural network (Kingma and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 210,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 212,
      "text": "Welling, 2014). In other words, the sampling of latent variables should be drawn from a fixed distribution",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 211,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 213,
      "text": "(without parameters) and then transformed to a desired sample using the distribution’s parameters. This",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 212,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 214,
      "text": "is nontrivial for Dirichlet distributions and further research is needed to address this problem.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 213,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 215,
      "text": "4 Experiments",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 195,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 216,
      "text": "We evaluated our model on two tasks: question generation (Section 4.1) and dialog systems (Section 4.2).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 215,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 217,
      "text": "4.1 Experiment I: Question Generation",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 216,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 218,
      "text": "Task, Dataset, and Metrics. We first evaluated our approach on a question generation task. It uses the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 216,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 219,
      "text": "Stanford Question Answering Dataset (Rajpurkar et al., 2016, SQuAD), and aims to generate questions",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 218,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 220,
      "text": "based on a sentence in a paragraph. We used the same train-validation-test split as in Du et al. (2017).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 219,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 5,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 221,
      "text": "Model Inference BLEU-1 BLEU-2 BLEU-3 BLEU-4 Entropy Dist-1 Dist-2DED (w/o Attn) (Du et al., 2017) MAP 31.34 13.79 7.36 4.26 - - -DED (w/o Attn) MAP 29.31 12.42 6.55 3.61 - - -DED+DAttn MAP 30.24 14.33 8.26 4.96 - - -VED+DAttn MAP 31.02 14.57 8.49 5.02 - - -Sampling 30.87 14.71 8.61 5.08 2.214 0.132 0.176VED+DAttn (2-stage training) MAP 28.88 13.02 7.33 4.16 - - -Sampling 29.25 13.21 7.45 4.25 2.241 0.140 0.188VED+VAttn-0 MAP 29.70 14.17 8.21 4.92 - - -Sampling 30.22 14.22 8.28 4.87 2.320 0.165 0.231VED+VAttn-¯h MAP 30.23 14.30 8.28 4.93 - - -Sampling 30.47 14.35 8.39 4.96 2.316 0.162 0.228",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 222,
      "text": "Table 2: BLEU, entropy, and distinct scores. We compare the deterministic encoder-decoder (DED)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 221,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 223,
      "text": "and variational encoder-decoders (VEDs). For VED, we have several variates: deterministic attention",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 222,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 224,
      "text": "(DAttn) and the proposed variational attention (VAttn). Variational models are evaluated by both max a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 223,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 225,
      "text": "posteriori (MAP) inference and sampling.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 224,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 226,
      "text": "According to Du et al. (2017), the attention mechanism is especially critical in this task in order to",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 218,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 227,
      "text": "generate relevant questions. Also, generated questions do need some variety (e.g., in the creation of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 226,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 228,
      "text": "reading comprehension datasets), as opposed to machine translation, which is typically deterministic.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 227,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 229,
      "text": "We followed Du et al. (2017) and used BLEU-1 to BLEU-4 scores (Papineni et al., 2002) to evaluate",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 226,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 230,
      "text": "the quality (in the sense of accuracy) of generated sentences. Besides, we adopted entropy and distinct",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 229,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 231,
      "text": "metrics to measure the diversity. Entropy is computed as − (cid:80)w p(w) log p(w), where p(·) is the unigram",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 230,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 232,
      "text": "probability in generated sentences. Distinct metrics—used in previous works to measure diversity (Li",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 231,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 233,
      "text": "et al., 2016)—computes the percentage of distinct unigrams or bigrams (denoted as Dist-1 and Dist-2,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 232,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 234,
      "text": "respectively).",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 233,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 235,
      "text": "Training Details. We used LSTM-RNNs with 100 hidden units for both the encoder and decoder;",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 229,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 236,
      "text": "the dimension of the latent vector z was also 100d. We adopted 300d word embeddings (Mikolov et al.,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 235,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 237,
      "text": "2013), pretrained on the SQuAD dataset. For both the source and target sides, the vocabulary was limited",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 236,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 238,
      "text": "to the most frequent 40k tokens. We used the Adam optimizer (Kingma and Ba, 2015) to train all models,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 237,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 239,
      "text": "with an initial learning rate of 0.005, a multiplicative decay of 0.95, and other default hyperparameters.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 238,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 240,
      "text": "The batch size was set to be 100.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 239,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 241,
      "text": "As shown in Bowman et al. (2016), Seq2Seq VAE is hard to train because of the issues associated",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 235,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 242,
      "text": "with the KL term vanishing to zero. Following Bowman et al. (2016), we adopted KL cost annealing",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 241,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 243,
      "text": "and word dropout during training. The coefficient of the KL term λKL was gradually increased using",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 242,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 244,
      "text": "a logistic annealing schedule, allowing the model to learn to reconstruct the input accurately during the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 243,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 245,
      "text": "early stages of training. A fixed word dropout rate of 25% was used.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 244,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 246,
      "text": "All the hyperparameter tuning was based on validation performance on the motivating Seq2Seq VAE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 241,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 247,
      "text": "discussed in Section 2.4, and the same hyperparameters were used for all of the models described in",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 246,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 248,
      "text": "Section 3.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 247,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 249,
      "text": "Overall Performance. Table 2 represents the performance of various models. We first implemented a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 246,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 250,
      "text": "traditional vanilla Seq2Seq model, which we call a deterministic encoder-decoder (DED), and generally",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 249,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 251,
      "text": "replicated the results on the question generation task as reported in Du et al. (2017), showing that our",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 250,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 252,
      "text": "implementation is fair. Incorporating attention mechanism in this model (DED+DAttn) improves BLEU",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 251,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 253,
      "text": "scores, as expected. In the variational encoder-decoder (VED) framework, we report results obtained by",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 252,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 254,
      "text": "both max a posterior (MAP) inference as well as sampling. In the sampling setting, we draw 10 samples",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 253,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 255,
      "text": "(z and/or a) from the posterior given x for each data point, and report average BLEU scores.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 254,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 256,
      "text": "The proposed variational attention model (VED+VAttn) largely outperforms deterministic attention",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 249,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 257,
      "text": "(VED+DAttn) in terms of all diversity metrics. It should be noted that entropy is a logarithmic measure,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 256,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 6,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 258,
      "text": "IMAGE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 259,
      "text": "Figure 4: BLEU-2, BLEU-4, Entropy, and Dist-1 calculated on the validation set as training progresses.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 256,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 260,
      "text": "IMAGE",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 259,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 261,
      "text": "Figure 5: BLEU-2, BLEU-4, Entropy, and Dist-1 with different γa values.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 260,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 262,
      "text": "and hence a difference of 0.1 in Table 2 is significant; VED+VAttn also generates more distinct unigrams",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 259,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 263,
      "text": "and bigrams than VED+DAttn.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 262,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 264,
      "text": "Regarding the prior of variational attention, we propose two variants: N (0, I) and N ( ¯h(src) , I), de-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 262,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 265,
      "text": "noted as VED+VAttn-0 and VED+VAttn- ¯h, respectively. VED+VAttn-0 has slightly lower BLEU but",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 264,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 266,
      "text": "higher diversity. The results are generally comparable, showing both priors are reasonable.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 265,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 267,
      "text": "We also tried a heuristic of 2-stage training (VED+DAttn 2-stage), in which the VED is first trained",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 264,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 268,
      "text": "without attention for 6 epochs, and then the attention mechanism is added to the model. This heuristic is",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 267,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 269,
      "text": "proposed in hopes of better training the variational latent space at the beginning stages. However, exper-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 268,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 270,
      "text": "iments show that such simple heuristic does not help much, and is worse than the principled variational",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 269,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 271,
      "text": "attention mechanism in terms of all BLEU and diversity metrics.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 270,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 272,
      "text": "Human Evaluation. In order to assess the quality of the generated text in terms of language fluency,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 264,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 273,
      "text": "a human evaluation study was carried out. For each of the two models under comparison (VED+DAttn",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 272,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 274,
      "text": "and VED+VAttn-¯h), a randomly shuffled subset of 100 generated questions were selected. Six human",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 273,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 275,
      "text": "evaluators were asked to rate the fluency of these 200 questions on a 5-point scale: 5-Flawless, 4-Good,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 274,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 276,
      "text": "3-Adequate, 2-Poor, 1-Incomprehensible, following Stent et al. (2005). The average rating obtained for",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 275,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 277,
      "text": "VED+DAttn was 3.99 and for VED+VAttn- ¯h was 4.01, the difference between which is not statistically",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 276,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 278,
      "text": "significant. The human annotations achieved 0.61 average Spearman correlation coefficient (measuring",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 277,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 279,
      "text": "order correlation) between any two annotators. According to Swinscow (1976), this indicates moderate",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 278,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 280,
      "text": "to strong correlation among different annotators. Hence, we conclude variational attention does not",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 279,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 281,
      "text": "negatively affect the fluency of sentences.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 280,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 282,
      "text": "Learning curves. Figure 4 shows the trends of sentence quality (BLEU-2 and BLEU-4) and diversity",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 272,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 283,
      "text": "(entropy and Dist-1) of all models on the validation set, as training progresses.2 We see that BLEU",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 282,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 284,
      "text": "and diversity are conflicting objectives: a high BLEU score indicates resemblance to the groundtruth,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 283,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 285,
      "text": "resulting in low diversity. However, the variational attention mechanisms (red and green lines in Figure 4)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 284,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 286,
      "text": "remain high in both aspects, showing the effectiveness of our model.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 285,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 287,
      "text": "Strength of Attention’s KL Loss. We tuned the KL term’s strength in variational attention, i.e., γa",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 282,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 288,
      "text": "in Eq. (8), and plot the BLEU and diversity metrics in Figure 5. In this experiment, we used the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 287,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 289,
      "text": "VED+DAttn-¯h variant. As shown, a decrease in γa increases the quality of generated sentences at the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 288,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 290,
      "text": "2 Other metrics are omitted because the trend is the same.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": 289,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 7,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 291,
      "text": "Source when the british forces evacuated at the close of the war in 1783 ,they transported 3,000 freedmen for resettlement in nova scotia .Reference in what year did the american revolutionary war end ?VED+DAttn how many people evacuated in newfoundland ?how many people evacuated in newfoundland ?what did the british forces seize in the war ?VED+Vattn-¯h how many people lived in nova scotia ?where did the british forces retreat ?when did the british forces leave the war ? Source downstream , more than 200,000 people were evacuated frommianyang by june 1 in anticipation of the dam bursting .Reference how many people were evacuated downstream ?VED+DAttn how many people evacuated from the mianyang basin ?how many people evacuated from the mianyang basin ?how many people evacuated from the mianyang basin ?VED+VAttn- ¯h how many people evacuated from the tunnel ?how many people evacuated from the dam ?how many people were evacuated from fort in the dam ?",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 292,
      "text": "Table 3: Case study of question generation.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 291,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 293,
      "text": "Model Inference BLEU-2 Entropy Dist-1 Dist-2DED+DAttn MAP 1.84 – – –VED+DAttn MAP 1.68 – – –Sampling 1.68 2.113 0.311 0.450VED+VAttn-¯h MAP 1.78 – – –Sampling 1.79 2.167 0.324 0.467",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": -1,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 294,
      "text": "Table 4: Performance on conversation systems.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 293,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 295,
      "text": "cost of diversity. This is expected because a lower γa gives the model less incentive to optimize the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 287,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 296,
      "text": "attention’s KL term, which then causes the model to behave more “deterministic.” Based on this experi-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 295,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 297,
      "text": "ment, we chose a value of 0.1 for γa , as it yields a learning curve in the middle among those of different",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 296,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 298,
      "text": "hyperparameters, being a good balance between quality and diversity.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 297,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 299,
      "text": "It should be further mentioned that, with a milder γa (e.g., 0.01), VED+VAttn outperforms",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 287,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 300,
      "text": "VED+DAttn in terms of both quality and diversity (on the validation set). This is consistent with the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 299,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 301,
      "text": "evidence that variational latent space may serve as a way of regularization and improves quality (Zhang",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 300,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 302,
      "text": "et al., 2016). However, a small γa only slightly improves diversity, and hence we did not choose this",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 301,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 303,
      "text": "hyperparameter in Table 2.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 302,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 304,
      "text": "Case study. We show in Table 3 two examples of generated sentences by VED+DAttn and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 299,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 305,
      "text": "VED+VAttn-¯h, each containing three random sentences drawn from the variational latent space(s) for",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 304,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 306,
      "text": "a given input. In both examples, the variational attention generates more diversified sentences than de-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 305,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 307,
      "text": "terministic attention. The quality of generated sentences is close in both models.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 306,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 308,
      "text": "4.2 Experiment II: Dialog Systems",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 183,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 309,
      "text": "We present another experiment on generative conversation systems. The goal is to generate a reply based",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 308,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 310,
      "text": "on a user-issued utterance. We used the Cornell Movie-Dialogs Corpus3 (Danescu-Niculescu-Mizil and",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 309,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 311,
      "text": "Lee, 2011) as our dataset, which contains more than 200k conversational exchanges. All the settings",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 310,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 312,
      "text": "in this experiment were the same as in Subsection 4.1 except that we had 30k words as the vocabulary",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 311,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 313,
      "text": "for both the encoder and decoder. We evaluated the quality of generated replies with BLEU-2, as it has",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 312,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 314,
      "text": "been observed to be more or less correlated with human annotators among the BLEU metrics (Liu et al.,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 313,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 315,
      "text": "2016).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 314,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 316,
      "text": "Table 4 shows the performance of our model (VED-VAttn-¯h) compared with two main baselines.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 309,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 317,
      "text": "We see that VEDs are slightly worse than the deterministic encoder-decoder (DED) in this experiment.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 316,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 318,
      "text": "However, variational attention outperforms deterministic attention in terms of both quality and diversity,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 317,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 319,
      "text": "showing that our model is effective in different applications. However, we find the improvement is not",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 318,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 320,
      "text": "so large as in the previous experiment. We conjecture that in conversational systems, there is a weaker",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 319,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 321,
      "text": "alignment between the source and target information. Hence, the attention mechanism itself is less",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 320,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 322,
      "text": "effective.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 321,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 323,
      "text": "5 Related Work",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 308,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 324,
      "text": "3 https://www.cs.cornell.edu/˜cristian/Cornell_Movie- Dialogs_Corpus.html",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": true,
      "parent": 323,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 8,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 325,
      "text": "The variational autoencoder (VAE) was proposed by Kingma and Welling (2014) for image generation.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 324,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 326,
      "text": "In NLP, it has been used to generate sentences (Bowman et al., 2016). Serban et al. (2017) propose a",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 325,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 327,
      "text": "variational encoder-decoder (VED) model to generate better (more diverse and thus meaningful) replies",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 326,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 328,
      "text": "in a dialog system. VED frameworks have also been applied to knowledge base reasoning (Zhang et al.,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 327,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 329,
      "text": "2018). Another thread of VAE/VED applications is to control some characteristics of generated data,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 328,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 330,
      "text": "such as the angle of a face image (Kumar et al., 2017), and the sentiment of a sentence (Hu et al., 2017).",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 329,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 331,
      "text": "In this paper, the focus is on the scenario where VED is combined with attention mechanism. We",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 330,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 332,
      "text": "show that the variational attention space is effective, in terms of the diversity of sampled sentences (since",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 331,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 333,
      "text": "VEDs are probabilistic models). Although previous studies have addressed diversity using diversified",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 332,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 334,
      "text": "beam search (Vijayakumar et al., 2016) and determinantal point processes (Song et al., 2018), we would",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 333,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 335,
      "text": "like to point out that our paper is “orthogonal” to those studies. The diversity in our approach arises",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 334,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 336,
      "text": "through probabilistic modeling, as opposed to a manually specified heuristic function of the diversity",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 335,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 337,
      "text": "metric. It is to be noted that our approach can be naturally combined with the above methods.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 336,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 338,
      "text": "6 Conclusion and Future Work",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 323,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 339,
      "text": "In this paper, we proposed a variational attention mechanism for variational encoder-decoder (VED)",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 338,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 340,
      "text": "frameworks. We observe that, in VEDs, if the decoder has direct access to the encoder, the connection",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 339,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 341,
      "text": "may bypass the variational space. Traditional attention mechanisms might serve as bypassing connection,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 340,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 342,
      "text": "making the output less diverse. Our variational attention mechanism imposes a probabilistic distribution",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 341,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 343,
      "text": "on the attention vector. We also proposed different priors for the attention vector. The proposed model",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 342,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 344,
      "text": "was evaluated on two tasks: question generation and dialog systems, showing that variational attention",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 343,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 345,
      "text": "yields more diversified samples while retaining high quality.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 344,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 346,
      "text": "In future work, it would be interesting to investigate VEDs that model the attention probability with",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 339,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 347,
      "text": "Dirichlet distributions (see Figure 3d). Our framework also provides a principled methodology for de-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 346,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 348,
      "text": "signing variational encoding-decoding models without the bypassing phenomenon.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 347,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 349,
      "text": "Acknowledgments",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 323,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 350,
      "text": "We thank Hao Zhou for helpful discussions. The Titan Xp GPU used for this research was donated by",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 349,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 351,
      "text": "the NVIDIA Corporation to Olga Vechtomova.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 350,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 352,
      "text": "References",
      "label_id": 4,
      "label_name": "Section",
      "is_meta": false,
      "parent": 349,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 353,
      "text": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 352,
      "rel_id": 1,
      "rel_name": "contain",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 354,
      "text": "align and translate. In Proceedings of the International Conference on Learning Representations.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 353,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 355,
      "text": "Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 353,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 356,
      "text": "corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 355,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 357,
      "text": "in Natural Language Processing, pages 632–642.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 356,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 358,
      "text": "Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio. 2016. Gen-",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 355,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 359,
      "text": "erating sentences from a continuous space. In Proceedings of the 20th SIGNLL Conference on Computational",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 358,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 360,
      "text": "Natural Language Learning, pages 10–21.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 359,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 361,
      "text": "Kris Cao and Stephen Clark. 2017. Latent variable dialogue models and their diversity. In Proceedings of the 15th",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 358,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 362,
      "text": "Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 361,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 363,
      "text": "pages 182–187.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 362,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 364,
      "text": "Cristian Danescu-Niculescu-Mizil and Lillian Lee. 2011. Chameleons in imagined conversations: A new approach",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 361,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 365,
      "text": "to understanding coordination of linguistic style in dialogs. In Proceedings of the Workshop on Cognitive",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 364,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 366,
      "text": "Modeling and Computational Linguistics, pages 76–87.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 365,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 367,
      "text": "Xinya Du, Junru Shao, and Claire Cardie. 2017. Learning to ask: Neural question generation for reading compre-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 364,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 368,
      "text": "hension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 367,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 369,
      "text": "1: Long Papers), pages 1342–1352.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 368,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 370,
      "text": "Geoffrey E Hinton and Ruslan R Salakhutdinov. 2006. Reducing the dimensionality of data with neural networks.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 367,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 371,
      "text": "Science, 313(5786):504–507.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 370,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 9,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 372,
      "text": "Sepp Hochreiter and J ¨urgen Schmidhuber. 1997. Long short-term memory. Neural Computation, 9(8):1735–",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 370,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 373,
      "text": "1780.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 372,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 374,
      "text": "Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P. Xing. 2017. Toward controlled",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 372,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 375,
      "text": "generation of text. In Proceedings of the 34th International Conference on Machine Learning, pages 1587–",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 374,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 376,
      "text": "1596.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 375,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 377,
      "text": "Diederik Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In Proceedings of the",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 370,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 378,
      "text": "International Conference on Learning Representations.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 377,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 379,
      "text": "Diederik P Kingma and Max Welling. 2014. Auto-encoding variational Bayes. In Proceedings of the International",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 377,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 380,
      "text": "Conference on Learning Representations.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 379,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 381,
      "text": "Abhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan. 2017. Variational inference of disentangled latent",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 379,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 382,
      "text": "concepts from unlabeled observations. arXiv preprint arXiv:1711.00848.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 381,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 383,
      "text": "Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016. A diversity-promoting objective",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 381,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 384,
      "text": "function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 383,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 385,
      "text": "of the Association for Computational Linguistics: Human Language Technologies, pages 110–119.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 384,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 386,
      "text": "Chia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Noseworthy, Laurent Charlin, and Joelle Pineau. 2016. How NOT",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 383,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 387,
      "text": "to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 386,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 388,
      "text": "generation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 387,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 389,
      "text": "pages 2122–2132.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 388,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 390,
      "text": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 386,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 391,
      "text": "words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 390,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 392,
      "text": "3111–3119.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 391,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 393,
      "text": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: A method for automatic eval-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 390,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 394,
      "text": "uation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 393,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 395,
      "text": "Linguistics, pages 311–318.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 394,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 396,
      "text": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 393,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 397,
      "text": "machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 396,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 398,
      "text": "Language Processing, pages 2383–2392.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 397,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 399,
      "text": "Alexander M. Rush, Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sentence",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 396,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 400,
      "text": "summarization. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 399,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 401,
      "text": "pages 379–389.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 400,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 402,
      "text": "Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron C Courville, and",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 399,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 403,
      "text": "Yoshua Bengio. 2017. A hierarchical latent variable encoder-decoder model for generating dialogues. In",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 402,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 404,
      "text": "Proceedings of the 31st AAAI Conference on Artificial Intelligence, pages 3295–3301.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 403,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 405,
      "text": "Yiping Song, Rui Yan, Yansong Feng, Yaoyuan Zhang, Zhao DongYan, and Ming Zhang. 2018. Towards a neural",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 402,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 406,
      "text": "conversation model with diversity net using determinantal point processes. In Proceedings of the 32nd AAAI",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 405,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 407,
      "text": "Conference on Artificial Intelligence, pages 5932–5939.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 406,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 408,
      "text": "Amanda Stent, Matthew Marge, and Mohit Singhai. 2005. Evaluating evaluation methods for generation in the",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 405,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 409,
      "text": "presence of variation. In Proceedings of International Conference on Intelligent Text Processing and Computa-",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 408,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 410,
      "text": "tional Linguistics, pages 341–351.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 409,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 411,
      "text": "TD Swinscow. 1976. Statistics at square one: Xviii-correlation. British Medical Journal, 2(6037):680.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 408,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 412,
      "text": "Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R Selvaraju, Qing Sun, Stefan Lee, David Crandall, and",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 411,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 413,
      "text": "Dhruv Batra. 2016. Diverse beam search: Decoding diverse solutions from neural sequence models. arXiv",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 412,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 414,
      "text": "preprint arXiv:1610.02424.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 413,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 415,
      "text": "Martin J Wainwright, Michael I Jordan, et al. 2008. Graphical models, exponential families, and variational",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 412,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 416,
      "text": "inference. Foundations and Trends® in Machine Learning, pages 1–305.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 415,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 417,
      "text": "Biao Zhang, Deyi Xiong, jinsong su, Hong Duan, and Min Zhang. 2016. Variational neural machine translation.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 415,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 418,
      "text": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 521–530.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 417,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 419,
      "text": "Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander J Smola, and Le Song. 2018. Variational reasoning",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 418,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 420,
      "text": "for question answering with knowledge graph. In Proceedings of the 32nd AAAI Conference on Artificial",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 419,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 421,
      "text": "Intelligence.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 420,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 10,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 422,
      "text": "Zaixiang Zheng, Hao Zhou, Shujian Huang, Lili Mou, Xinyu Dai, Jiajun Chen, and Zhaopeng Tu. 2018. Modeling",
      "label_id": 5,
      "label_name": "First-Line",
      "is_meta": false,
      "parent": 419,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 423,
      "text": "past and future for neural machine translation. Transactions of the Association for Computational Linguistics,",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 422,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 424,
      "text": "pages 145–157.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 423,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 425,
      "text": "Chunting Zhou and Graham Neubig. 2017. Morphological inflection generation with multi-space variational",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 422,
      "rel_id": 2,
      "rel_name": "equality",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 426,
      "text": "encoder-decoders. In Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 425,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    },
    {
      "id": 427,
      "text": "Reinflection, pages 58–65.",
      "label_id": 6,
      "label_name": "Para-Line",
      "is_meta": false,
      "parent": 426,
      "rel_id": 0,
      "rel_name": "connect",
      "page_id": 11,
      "box": [
        0,
        0,
        0,
        0
      ]
    }
  ]
}